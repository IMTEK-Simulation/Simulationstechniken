{"0": {
    "doc": "General remarks",
    "title": "General remarks",
    "content": "Further reading . The lecture material will guide through the basics of the molecular dynamics simulation method. It will give you enough information to complete the associated project. The appendix dives deeper in specific topics. As additional reading material, we recommend the following books: . | Molecular dynamics: Michael P. Allen, Dominic J. Tildeley, Computer simulations of liquids, Oxford University Press - link to publisher . | Statistical mechanics: James P. Sethna, Entropy, order parameters, and complexity, Oxford University Press - link to free PDF . | Interatomic forces: Mike Finnis, Interatomic forces in condensed matter, Oxford University Press - link to publisher . | . ",
    "url": "http://localhost:4000/_lecture/chapter00.html",
    "relUrl": "/_lecture/chapter00.html"
  },"1": {
    "doc": "Chapter 01",
    "title": "Chapter 1\nIntroduction",
    "content": "Context: We start by introducing the concept of the potential energy and the interatomic force. Those are the central ingredients to the molecular dynamics simulation method. 1.1 Structure of matter at the atomic scale . All matter is build out of quark and leptons, or perhaps even smaller particles, but for the sake of modeling the real material world the atom is the fundamental unit. Atoms can be described by nuclei and electrons or through “coarse-grained” models that ignore the fact that there are electrons. Both types of models are useful for describing materials, and the latter ones will be extensively used in this class. Atoms in solids can arrange in different configurations that are called crystals when there is long-ranged order or glasses when there is not. (All solid matter typically has short-ranged order that is determined by the chemical bonds between atoms.) Atoms in solids are immobile and self-diffusion is limited. Conversely, liquids and gases are disordered (like glasses) but have mobile constituent atoms. Macroscopic object typically contain a lot of atoms – on the order of Avogadro’s constant \\(N_A\\approx 6\\times 10^{23}\\). The atomic-scale simulation techniques discussed in this class can at the time of this writing (2020) treat on order of \\(\\sim 10^6\\) atoms, \\(10^8-10^9\\) if you use the biggest computers available to us. Of course, this boundary is pushed towards larger systems as computer technology evolves. We can nowadays even observe matter at atomic scales and “see” individual atoms. The collaborative research center 103 has produced an extremely instructive video on the structure of specific type of alloys, dubbed “superalloy”, that is used in e.g. turbine blades. Enjoy the ride from the blade to the atom. This class is about modeling matter at the smallest scales that you see in this video. https://www.youtube.com/embed/wYHch5QIWTQ . 1.2 Interatomic forces and the potential energy . https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=a12a8064-84e7-47f6-80ab-ad15014bae8a . Atoms interact via forces. As Feynman put it in his famous lectures on physics, the fundamental truth about man’s understanding of the physical world is “that all things are made of atoms – little particles that move around in perpetual motion, attracting each other when they are a little distance apart, but repelling upon being squeezed into one another”. Indeed this is the essence of the molecular dynamics simulation method. As the simplest example why atoms attract each other, let us consider the example of simple salt, e.g. Na-Cl that we all have sitting in our kitchen. Na-Cl in its solid form is an ionic crystal. Na atoms have approximately a charge of \\(q_{\\text{Na}}=+1|e|\\), where \\(e\\) is the electron charge, and Cl atoms have a charge of approximately \\(q_{\\text{Na}}=-1|e|\\). The Coulomb interaction between these atoms is a fundamental force of nature. Basic physical principles tell us, that the interaction energy between a Na and a Cl atom is given by \\begin{equation} V_{\\text{Coulomb}}(r;q_{\\text{Na}},q_{\\text{Cl}}) = \\frac{1}{4\\pi \\varepsilon _0} \\frac{q_{\\text{Na}} q_{\\text{Cl}}}{r}. \\end{equation} We also know that this energy is pair-wise additive, allowing us to write down the Coulomb interaction energy for Na-Cl consisting of \\(N\\) atoms, \\begin{equation} E_{\\text{Coulomb}}(\\{\\vec{r}_i\\}) = \\sum _{i=1}^N \\sum _{j=i+1}^N V_{\\text{Coulomb}}(r_{ij};q_i, q_j) = \\frac{1}{4\\pi \\varepsilon _0} \\sum _{i=1}^N \\sum _{j=i+1}^N \\frac{q_i q_j}{r_{ij}} \\label{eqn:coulomb} \\end{equation} where \\(q_i\\) is the charge on atom \\(i\\) and \\(r_{ij}=|\\vec{r}_i - \\vec{r}_j|\\) the distance between atom \\(i\\) and \\(j\\). Note that we have introduced — in passing — a central quantity of the molecular dynamics method, the atomic positions \\(\\vec{r}_i\\) and Eq. \\eqref{eqn:coulomb} indicates that the interaction energy depends on the positions of all atoms. The Coulomb interaction has a singularity at \\(r\\to 0\\). The attractive force between opposite charges becomes infinitely large. The salt crystal does not collapse because atoms are, as Feynman puts it, “repelling upon being squeezed into one another”. While the attraction between our Na and Cl atoms are described by a fundamental force of nature, it is more difficult to understand the origin of this repulsion. Hand-wavingly, it goes back to the fact that electrons are Fermions and electrons from the electron shells of Na and Cl therefore cannot exist at the same point in space (and the same spin state). This is the Pauli exclusion principle and the resulting repulsive force is called Pauli repulsion. Different models for the Pauli repulsion exist. While the Coulomb interaction is a fundamental force of nature, these models are approximations to the true quantum physics that is the origin of the repulsive form. Two common forms are exponential repulsion, \\begin{equation} E_{\\text{rep,exp}}(\\{\\vec{r}_i\\}) = \\sum _{i=1}^N \\sum _{j=i+1}^N A e^{-r/\\rho }, \\end{equation} or an algebraic repulsion of the form \\begin{equation} E_{\\text{rep,12}}(\\{\\vec{r}_i\\}) = \\sum _{i=1}^N \\sum _{j=i+1}^N A r^{-12}. \\end{equation} Note that \\(A\\) and \\(\\rho \\) are parameters, that need to be somehow determined. This can be done with the help of either experimental data or first-principles calculations, that treat the electrons explicitly. These parameters depend on the atom types under consideration and in contrast to the parameter that show up in the Coulomb interaction (the permittivity \\(\\varepsilon _0\\)), they are not universal. For our Na-Cl model, we combine Coulomb interaction with an exponential repulsion, to give the total energy \\begin{equation} E_{\\text{pot}}(\\{\\vec{r}_i\\}) = \\sum _{i=1}^N \\sum _{j=i+1}^N \\left (A_{ij} e^{-r_{ij}/\\rho _{ij}} + \\frac{1}{4\\pi \\varepsilon _0} \\frac{q_i q_j}{r_{ij}}\\right ). \\label{eqn:NaCl} \\end{equation} This energy is called the potential energy and is the central property of an atomic-scale model. With Eq. \\eqref{eqn:NaCl}, we have also encountered our first atomic-scale model for a real material. Potentials that can be decomposed as Eq. \\eqref{eqn:NaCl} into pair-wise terms are called pair potentials. They are often written as \\begin{equation} E_{\\text{pot}}(\\{\\vec{r}_i\\}) = \\sum _{i=1}^N \\sum _{j=i+1}^N V(r_{ij}), \\end{equation} with \\begin{equation} V(r_{ij}) = A_{ij} e^{-r_{ij}/\\rho _{ij}} + \\frac{1}{4\\pi \\varepsilon _0} \\frac{q_i q_j}{r_{ij}} \\end{equation} for the above potential. The quantity \\(V(r_{ij})\\) is called the pair interaction energy. Likely the most famous pair-potential is the Lennard-Jones potential. Its pair interaction energy is given by \\begin{equation} V(r_{ij}) = 4\\varepsilon \\left [\\left (\\frac{\\sigma }{r}\\right )^{12} - \\left (\\frac{\\sigma }{r}\\right )^6\\right ]. \\end{equation} The repulsive term \\(\\propto r^{-12}\\) is one of the models for Pauli repulsion discussed above. The attractive term \\(\\propto r^{-6}\\) arises from London dispersion interactions. Dispersion forces exist between all atoms, even uncharged molecules or noble gases. They are widely employed for the nonbonded portion of valence force-fields. Simple Lennard-Jones systems are often used to study generic phenomena found in real materials, e.g. for example the glass transition or plasticity of amorphous materials. There are limitations of pair potentials and more sophisticated potential energy models have been developed over the past decades. We will discuss a few of those in Chapter ??. Note: A repulsive term of the form \\(r^{-12}\\) is more attractive from a simulation point of view since it is faster to compute than an exponential. This has helped popularize the Lennard-Jones potential in the early days of molecular dynamics simulations. The significance of the potential energy is that we can derive forces from it, \\begin{equation} \\vec{f}_k = -\\frac{\\partial }{\\partial \\vec{r}_k} E_{\\text{pot}}(\\{\\vec{r}_i\\}). \\label{eq:forces} \\end{equation} These forces are the essential ingredient to molecular dynamics, as they determine the motion of the atoms. The potential energy itself describes what is called the potential energy landscape. The potential energy landscape depends on \\(3N\\) degrees of freedom (as compared to the landscape we experience while walking, which depends on \\(2\\) degrees of freedom); it is therefore an object that is complex to visualize. Simplifying aspects of it is the core of molecular statics. For example, it is typically important to at least identify the ground-state of a system; this is the most stable configuration of a material and has the lowest possible potential energy. There is usually some crystal that is lower in energy than the energy of a glass with the same stoichiometry. Yet, in many real-world engineering applications the materials are not in their crystalline ground-state, the most common material we encounter with this property may be window glass. In molecular statics we therefore seek to enumerate those local minima of the potential energy landscape and energy barriers between them. Since the dynamics of a molecular system is determined by the forces, we only need to specify the potential energy up to a constant which disappears in the derivative Eq. \\eqref{eq:forces}. We can therefore measure the potential energy with respect to any reference configuration. This reference configuration is often the atomized state of the material, where all of the constituent atoms sit individually in vacuum and are not interacting with each other. If this reference situation is assigned the energy \\(0\\), then the potential energy is generally negative, because if it was positive the system would spontaneously atomize. (Remember, any physical system evolves to a state of lower energy.) . ",
    "url": "http://localhost:4000/_lecture/chapter01.html#x1-10001",
    "relUrl": "/_lecture/chapter01.html#x1-10001"
  },"2": {
    "doc": "Chapter 01",
    "title": "Bibliography",
    "content": " ",
    "url": "http://localhost:4000/_lecture/chapter01.html#x1-40001.2",
    "relUrl": "/_lecture/chapter01.html#x1-40001.2"
  },"3": {
    "doc": "Chapter 01",
    "title": "Chapter 01",
    "content": ". ",
    "url": "http://localhost:4000/_lecture/chapter01.html",
    "relUrl": "/_lecture/chapter01.html"
  },"4": {
    "doc": "Chapter 02",
    "title": "Chapter 2\nMolecular dynamics",
    "content": "Context: Molecular dynamics follows the motion of individual atoms through a solution of Newton’s equations of motion. We need integration algorithms to be able to solve this set of coupled differential equations on a computer. 2.1 Equations of motion . https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=d3188a05-4143-4602-b6c2-ad15014fe21d . 2.1.1 Newton’s equations of motion . We have now (almost) all the ingredients to carry out a molecular dynamics simulation. From our or potential energy expression \\(E_{\\text{pot}}(\\{\\vec{r}_i\\})\\) discussed in the previous chapter, we obtain the force \\begin{equation} \\vec{f}_i = \\partial E_{\\text{pot}}/\\partial \\vec{r}_i \\end{equation} on each of the \\(N\\) atoms. Once we know the forces, we can obtain the accelerations \\(\\vec{a}_i\\) through Newton’s third law, \\begin{equation} \\vec{f}_i = m_i \\vec{a}_i. \\end{equation} We are therefore assuming that atom \\(i\\) can be described as a point of mass \\(m_i\\)! The mass can be obtained from the periodic table of elements. Note that the mass listed in the periodic table is usually the average over all isotopes weighted by their occurrence on earth, and this mass is used for most practical purposes. For some application, in particular to understand the different behavior of Hydrogen and Deuterium, it can be necessary to actually model the individual isotopes by using their respective mass. We further have \\(\\vec{a}_i = \\dot{\\vec{v}}_i\\), where \\(\\vec{v}_i\\) is the velocity of atom \\(i\\), and \\(\\vec{v}_i = \\dot{\\vec{r}}_i\\). The dot superscript indicates derivative with respect to time. The set of linear differential equations to solve is therefore \\begin{equation} \\dot{v}_i(t) = \\vec{f}_i(t)/m_i\\{\\text{ and} }\\ \\dot{\\vec{r}}_i(t) = \\vec{v}_i(t) \\label{eq:Newton} \\end{equation} with the initial (boundary) conditions \\(\\vec{r}_i(0) = \\vec{r}_0\\) and \\(\\vec{v}_i(0) = \\vec{v}_0\\). Note that the boundary condition is an integral part of the differential Eq. \\eqref{eq:Newton}. The state of the system is therefore fully and uniquely determined by the positions \\(\\vec{r}_i\\) and the velocities \\(\\vec{v}_i\\) of all atoms. This set of positions \\(\\vec{r}_i\\) and momenta \\(\\vec{p}_i = \\vec{v}_i/m_i\\) defines a point in phase-space \\(\\vec{\\Gamma } = \\{ \\vec{r}_i, \\vec{p}_i\\}\\). The evolution of position and velocities given by Eq. \\eqref{eq:Newton} can therefore be thought of as a single point moving in the \\(6N\\) dimensional phase-space. The concept of a phase-space will become important in the next chapter when we talk about statistical mechanics. Code example: For a molecular dynamics code, it is useful to have a data structure that represents the state of the simulation and stores at least positions and velocities. This data structure could also store element names (or atomic numbers), masses and forces. An example that uses Eigen arrays as the basic array container is shown below. 1using Positions_t = Eigen::Array3Xd;  2using Velocities_t = Eigen::Array3Xd;  3using Forces_t = Eigen::Array3Xd;  4  5class Atoms {  6public:  7    Positions_t positions;  8    Velocities_t velocities;  9    Forces_t forces;  10  11    Atoms(Positions_t &amp;p) :  12            positions{p}, velocities{3, p.cols()}, forces{3, p.cols()} {  13        velocities.setZero();  14        forces.setZero();  15    }  16  17    size_t nb_atoms() const {  18        return positions.cols();  19    }  20}; As a general rule, the data structure should be designed in a way that data that is processed consecutively is also stored in memory in a continuous manner. This ensures cache coherenece. For example, we could be tempted to create a class Atom that contains the positions, velocities, etc. of a single atom and than use an array (e.g. std::vector&lt;Atom&gt; atoms) of that class as the basic data structure. However, positions are then no longer consecutive in memory. A function (e.g. computing forces) does not need the velocities would still load them into the cache, as the cache line size for all modern CPUs is \\(64\\) bytes. For high-performance numerical code, it is therefore always preferable to use structures of arrays rather than arrays of structure. 2.1.2 Kinetic energy and energy conservation . In addition to the potential energy \\(E_{\\text{pot}}(\\{ \\vec{r}_i\\})\\), the dynamical state of a system is characterized by its kinetic energy, \\begin{equation} E_{\\text{kin}}(\\{ \\vec{p}_i\\}) = \\sum _i \\frac{1}{2} \\frac{p_i^2}{m_i}. \\end{equation} . Note: The temperature is simply a measure of the kinetic energy of the system, \\(\\frac{3}{2} N k_B T = E_{\\text{kin}}\\) where \\(N\\) is the number of atoms. In other words, \\(E_{\\text{kin}}\\) measures the variance of the velocity distribution, which is Gaussian. We will learn more about this when discussing the basics of statistical mechanics. The total energy \\begin{equation} H(\\{ \\vec{r}_i\\},\\{ \\vec{p}_i\\}) = E_{\\text{kin}}(\\{ \\vec{p}_i\\}) + E_{\\text{pot}}(\\{ \\vec{r}_i\\}) \\label{eq:hamil} \\end{equation} is a conserved quantity during the motion of the atoms. This can be seen by showing that the derivative of the total energy with respect to time vanishes, \\begin{equation} \\dot{H} = \\dot{E}_{\\text{kin}} + \\dot{E}_{\\text{pot}} = \\sum _i \\frac{\\vec{p}_i \\dot{\\vec{p}}_i}{m_i} + \\sum _i \\frac{\\partial E_{\\text{pot}}}{\\partial \\vec{r}_i} \\dot{\\vec{r_i}} = \\sum _i \\vec{v}_i \\vec{f}_i - \\sum _i \\vec{v}_i \\vec{f}_i = 0. \\end{equation} \\(H\\) is also called the Hamiltonian of the system. Note: Measuring the total energy (or any other conserved quantity!) and checking whether it is constant in a molecular dynamics simulation is a way of testing if the time step \\(\\Delta t\\) used in the numerical integration is small enough. We will discuss numerical integration in detail below. A generalization of Newton’s equations of motion are Hamilton’s equations of motion, \\begin{align} \\dot{\\vec{r}}_i &amp;= \\frac{\\partial H}{\\partial \\vec{p}_i} \\\\ \\dot{\\vec{p}}_i &amp;= -\\frac{\\partial H}{\\partial \\vec{r}_i}, \\end{align} . and it is straightforward to show that these equations reduce to Newton’s equations of motions for the Hamiltonian given by Eq. \\eqref{eq:hamil}. Hamilton’s equation of motion remain valid when positions \\(\\vec{r}_i\\) and momenta \\(\\vec{p}_i\\) are replaced by generalized coordinates that consider constraints, such as for example the angle of a (rigid) pendulum. These equations will become important when we discuss statistical mechanics and temperature control in molecular dynamics simulations using thermostats, where a generalized degree of freedom is the internal state of the heat bath that controls the temperature. A full derivation of Hamilton’s equations of motion is given in Chap. ??. 2.2 Integration algorithms . https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=50b66784-6560-4aea-8654-ad16004e1442 . The main ingredient in any molecular dynamics simulation, regardless of the underlying model, is the numerical solution of Eqs. \\eqref{eq:Newton}. A plethora of algorithms have been developed over the years, but for most practical purposes the Velocity-Verlet algorithm is used nowadays. For instructive purposes we will start out with a simple integration method, the Euler integration, before discussing Velocity-Verlet. 2.2.1 Euler integration . In order to follow the trajectories of all atoms we need to integrate the above differential equation. On a computer, a continuous differential equation needs to be replaced by a discrete equation. Equations \\eqref{eq:Newton} are continuous in time and hence need to be discretized. (Note that our system is already discrete spatially since we are dealing with mass points, but each of these points corresponds to a physical object so this is not the result of a discretization procedure.) The simplest integration is the Euler algorithm in which forces and velocities are assumed to be constant over time intervals \\(\\Delta t\\). To see this, we write the above differential equation as \\begin{equation} d \\vec{v}_i = \\frac{\\vec{f}_i(t)}{m_i}\\{\\text{ and} }\\ d\\vec{r}_i(t) = \\vec{v}_i(t)\\,dt \\end{equation} i.e., we move the differential \\(d t\\) of \\(\\dot{\\vec{v}}_i = d\\vec{v}/d t\\) to the right hand side of the equation. We can now straightforwardly integrate the equation from time \\(t\\) to time \\(t + \\Delta t\\) while assuming that \\(\\vec{f}_i\\) and \\(\\vec{v}_i\\) remain constant. This yields \\begin{align} \\vec{v}_i(t+\\Delta t) - \\vec{v}_i(t) &amp;= \\frac{\\vec{f}_i(t)}{m_i} \\Delta t \\label{eq:eulerexplicita} \\\\ \\vec{r}_i(t+\\Delta t) - \\vec{r}_i(t) &amp;= \\vec{v}_i(t) \\Delta t \\label{eq:eulerexplicitb} \\end{align} . which is obviously only a good approximation for small \\(\\Delta t\\)! This algorithm is called Euler integration. Same equation can be derived by Taylor-expanding \\(\\vec{r}_i(t+\\Delta t)\\) up to first order in \\(\\Delta t\\). The algorithm is hence \\(O(\\Delta t^2)\\). The Euler algorithm is not reversible, i.e. starting from time \\(t+\\Delta t\\) and integrating backwards one ends up with a different result at time \\(t\\). Applying the Euler algorithm with timestep \\(-\\Delta t\\) gives \\begin{align} \\vec{v}_i(t) - \\vec{v}_i(t+\\Delta t) &amp;= -\\frac{\\vec{f}_i(t+\\Delta t)}{m_i} \\Delta t \\\\ \\vec{r}_i(t) - \\vec{r}_i(t+\\Delta t) &amp;= -\\vec{v}_i(t+\\Delta t) \\Delta t \\end{align} . These equations cannot be re-arranged to give Eqs. \\eqref{eq:eulerexplicita} and \\eqref{eq:eulerexplicitb}. Euler integration is generally not a good algorithm and requires very small time steps. 2.2.2 Leap-frog integration . Leap-frog stores position at times \\(t_i\\) and velocities at times \\(t_i+\\Delta t/2\\) and can be derived from a argument similar to the one given above. Specifically, we combine the results of a Taylor expansion \\(\\pm \\Delta t/2\\), yielding \\begin{align} \\vec{v}_i(t+\\Delta t/2) - \\vec{v}_i(t-\\Delta t/2) &amp;= \\frac{\\vec{f}_i(t)}{m_i} \\Delta t \\label{eq:leapfrog1} \\\\ \\vec{r}_i(t+\\Delta t) - \\vec{r}_i(t) &amp;= \\vec{v}_i(t+\\Delta t/2) \\Delta t. \\end{align} . Note that Eq. \\eqref{eq:leapfrog1} is similar to Eq. \\eqref{eq:eulerexplicita}, except the force is evaluated at the mid-point. The resulting algorithm is reversible. Applying the Leap-frog algorithm with timestep \\(-\\Delta t\\) gives \\begin{align} \\vec{v}_i(t-\\Delta t/2) - \\vec{v}_i(t+\\Delta t/2) &amp;= -\\frac{\\vec{f}_i(t)}{m_i} \\Delta t \\\\ \\vec{r}_i(t) - \\vec{r}_i(t+\\Delta t) &amp;= -\\vec{v}_i(t+\\Delta t/2) \\Delta t \\end{align} . Bring the terms on the left hand side to the right and vice-versa, and you arrive at the original equations for forward integration. Leap-frog is therefore reversible. 2.2.3 Verlet integration . Let us now Taylor expand \\(\\vec{r}_i(t\\pm \\Delta t)\\) up to third order in \\(\\pm \\Delta t\\), \\begin{equation} \\label{eq:taylor_tplus} \\vec{r}_i(t\\pm \\Delta t) = \\vec{r}_i(t) \\pm \\vec{v}_i(t) \\Delta t + \\frac{1}{2m_i} \\vec{f}_i(t) \\Delta t^2 \\pm \\frac{1}{6} \\dot{\\dot{\\dot{\\vec{r}}}}_i(t) \\Delta t^3 + O(\\Delta t^4). \\end{equation} Note that only the odd exponents see the sign of \\(\\pm \\Delta t\\). The sum of this equation for expansion in \\(+\\Delta t\\) and \\(-\\Delta t\\) gives the positions update, \\begin{equation} \\vec{r}_i(t+\\Delta t) + \\vec{r}_i(t-\\Delta t) = 2\\vec{r}_i(t) + \\frac{1}{m_i} \\vec{f}_i(t) \\Delta t^2 + O(\\Delta t^4). \\label{eq:verlet} \\end{equation} Eq. \\eqref{eq:verlet} is called the Verlet algorithm. Instead of requiring the positions \\(\\{ \\vec{r}_i(t)\\}\\) and velocities \\(\\{ \\vec{v}_i(t)\\}\\) it requires the positions of the current \\(\\{ \\vec{r}_i(t)\\}\\) and past \\(\\{ \\vec{r}_i(t-\\Delta t)\\}\\) times for the integration. The difference between the expansion for \\(+\\Delta t\\) and \\(-\\Delta t\\) yields the velocities, \\begin{equation} \\vec{r}_i(t+\\Delta t) - \\vec{r}_i(t-\\Delta t) = 2\\vec{v}_i(t) \\Delta t + O(\\Delta t^3). \\end{equation} Note that in order to compute the velocities at time t in the regular Verlet algorithm, we need to know the positions at time \\(t + \\Delta t\\). Verlet and Leap-Frog are identical algorithms, since Leap-Frog stores the velocities at the intermediate time \\(t+\\Delta t/2\\). It is usually useful to be able to know both, positions and velocities, at time \\(t\\). This problem is solved by the Velocity-Verlet algorithm, described in the following section. 2.2.4 Velocity-Verlet integration . Let us now also Taylor expand \\(\\vec{r}_i(t)\\) up to third order in \\(\\Delta t\\) at \\(\\vec{r}_i(t+\\Delta t)\\), i.e. we integrate backwards in time from \\(t + \\Delta t\\) to \\(t\\). This gives \\begin{equation} \\vec{r}_i(t) = \\vec{r}_i(t+\\Delta t) - \\vec{v}_i(t+\\Delta t) \\Delta t + \\frac{1}{2m_i} \\vec{f}_i(t+\\Delta t) \\Delta t^2 - \\frac{1}{6} \\dot{\\dot{\\dot{\\vec{r}}}}_i(t) \\Delta t^3 + O(\\Delta t^3) \\label{eq:taylor_r} \\end{equation} Equation \\eqref{eq:taylor˙tplus} is the positions update of the Velocity-Verlet algorithm. The sum of Eq. \\eqref{eq:taylor˙tplus} and Eq. \\eqref{eq:taylor˙r} gives the velocity update in the Velocity-Verlet algorithm: \\begin{align} \\vec{r}_i(t+\\Delta t) &amp;= \\vec{r}_i(t) + \\vec{v}_i(t)\\Delta t + \\frac{1}{2m_i} \\vec{f}_i(t) \\Delta t^2\\\\ \\vec{v}_i(t+\\Delta t) &amp;= \\vec{v}_i(t) + \\frac{1}{2m_i} \\left (\\vec{f}_i(t) + \\vec{f}_i(t+\\Delta t) \\right ) \\Delta t, \\end{align} . Note that this algorithm is often split in the form of a predictor-corrector scheme since this saves computation time and the necessity to keep past forces around. The predictor step is \\begin{align} \\vec{v}_i(t+\\Delta t/2) &amp;= \\vec{v}_i(t) + \\frac{1}{2m_i} \\vec{f}_i(t) \\Delta t \\label{eq:vvpred1} \\\\ \\vec{r}_i(t+\\Delta t) &amp;= \\vec{r}_i(t) + \\vec{v}_i(t+\\Delta t/2) \\Delta t \\label{eq:vvpred2} \\end{align} . where \\(\\vec{v}_i(t+\\Delta t/2)\\) is the predicted velocity. After this we compute new forces, \\(\\vec{f}_i(t+\\Delta t)\\). We then correct the velocities via \\begin{equation} \\vec{v}_i(t+\\Delta t) = \\vec{v}_i(t+\\Delta t/2) + \\frac{1}{2m_i} \\vec{f}_i(t+\\Delta t) \\Delta t \\end{equation} The Velocity-Verlet algorithm is the integration algorithm used in most molecular dynamics codes. It has the additional properties that is it symplectic, which means it conserves phase-space volume. We will come back to what this mean when talking about statistical mechanics. Code example: We can implement the velocity-verlet algorithm in a few lines of C++ code using vectorized Eigen operations. The prediction step . 1void verlet_step1(Atoms &amp;atoms, double timestep, double mass) {  2    atoms.velocities += 0.5 * atoms.forces * timestep / mass;  3    atoms.positions += atoms.velocities * timestep;  4} implements Eq. \\eqref{eq:vvpred1}. We then compute new forces and correct the velocities via . 1void verlet_step2(Atoms &amp;atoms, double timestep, double mass) {  2    atoms.velocities += 0.5 * atoms.forces * timestep / mass;  3} Note: The timestep in MD simulations has to be on the order of femtoseconds, in order to resolve the fastest atomic vibrations. For example, in simulations with metals and Embedded Atom Method (EAM) potentials, \\(\\Delta t=1\\) fs is typically a safe choice. How can we check that the timestep is sensible? One possibility is to simply propage a configuration in time using the Velocity-Verlet algorithm. This is sometimes called the micro-canonical or NVE ensemble. (NVE because number of atoms, volume and energy is constant.) We then record the evolution of the total (kinetic plus potential) energy, which should be constant. The discrete time integration scheme will introduce numerical errors. If \\(\\Delta t\\) is too large, there will be noticeable drift of the total energy. The figures below show the results of such a simulation. A system of \\(108000\\) Au atoms was simulated for \\(100\\) ps with various values of \\(\\Delta t\\). The \\(y\\)-axis shows the difference between the current and initial values of the total energy. The data was smoothened to suppress high-frequency fluctuations in the figure. For this system, even \\(5\\) fs would still be an acceptable time step. ",
    "url": "http://localhost:4000/_lecture/chapter02.html#x1-10002",
    "relUrl": "/_lecture/chapter02.html#x1-10002"
  },"5": {
    "doc": "Chapter 02",
    "title": "Bibliography",
    "content": " ",
    "url": "http://localhost:4000/_lecture/chapter02.html#x1-100002.2.4",
    "relUrl": "/_lecture/chapter02.html#x1-100002.2.4"
  },"6": {
    "doc": "Chapter 02",
    "title": "Chapter 02",
    "content": ". ",
    "url": "http://localhost:4000/_lecture/chapter02.html",
    "relUrl": "/_lecture/chapter02.html"
  },"7": {
    "doc": "Chapter 03",
    "title": "Chapter 3\nPair potentials",
    "content": "Context: Interatomic forces or interatomic potentials determine the material that we want to study. There is a plethora of interatomic potentials of varying accuracy, transferability and computational cost available in the literature. We here discuss simple pair potentials and point out algorithmic considerations. 3.1 Introduction . https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=42ad47da-d1c1-48bc-9eda-ad2301538f4f . The expression for \\(E_\\text{pot}\\left (\\{ \\vec{r}_{i} \\} \\right )\\) is the model for the material that we use in our molecular dynamics calculations. It determines whether we model water, proteins, metals, or any other physical object. Models are typically characterized by their accuracy, their transferability and the computational cost involved. (Computational cost also includes the computational complexity.) At constant computational cost, there is always a tradeoff between accuracy and transferability. Accuracy and transferability can typically only be improved at the expense of additional computational cost. | Accuracy: How close to we get to the true, measured value. For example, the absolute error of vacancy formation energy \\(E_{\\text{vac}} - E_{\\text{vac}}^{\\exp }\\) with respect to experiment can be \\(1\\ \\text{eV}\\), \\(0.1\\ \\text{eV}\\) (typical), \\(0.01\\ \\text{eV}\\) (computationally expensive!). The vacancy formation energy is the energy required to remove a single atom from a solid. The resulting “hole” in the solid is called a vacancy. | Transferability: Let’s assume we get the vacancy formation energy right to within \\(0.1\\ \\text{eV}\\) of the experimental value. Does the interstitial formation energy, i.e. the energy to insert an additional atoms between lattice sites, give the same value? If so, then the potential is transferable between these two situations. Most interatomic potentials are not generally transferable, and they need to be tested when used in new situations, e.g. when the potential has been used to study crystals but you want to use it now to study a glass. | Computational cost: The number of floating point operations determine how expensive it is to compute an energy or a force. (Nowadays, actual energy requirement for doing the calculation would be a better measure.) This is related to computational complexity, that says how the computational cost (i.e. the number of operations requires to compute the result) scales with the number of atoms. We want \\(O(N)\\) complexity, but many methods scale worse. Quantum methods (tight-binding, density-functional theory) are usually \\(O(N^{3})\\) or worse. | . 3.2 Pair potentials . https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=35001264-ad07-4873-89f1-ad2301538f75 . We have already encountered the simplest (and oldest) form of an interaction potentials, the pair potential. The total energy for a system interacting in pairs can be written quite generally as \\begin{equation} E_\\text{pot}\\left ( \\{ \\vec{r}_{i} \\} \\right ) = \\frac{1}{2}\\sum _{i = 1}^{N}{\\sum _{j = 1}^{N}{V\\left ( r_{ij} \\right ) = \\sum _{i &lt; j} V(r_{ij})}} \\label{eq:pairpot} \\end{equation} where \\(r_{ij} = |\\vec{r}_{i} - \\vec{r}_{j}|\\) is the distance between atom i and atom j. \\(V(r_{ij})\\) is the pair interaction energy or just the pair potential and we assume that the interaction is pair-wise additive. The sum on the right (\\(\\sum _{i&lt;j}\\)) runs over all pairs while sum on the left double counts each pair and therefore needs the factor \\(1/2\\). We have already seen a combination of the electrostatic potential and Pauli repulsion as an example of a pair-potential earlier. Forces are computed by taking the negative gradient of this expression. The force on atom \\(k\\) is given by \\begin{equation} \\vec{f}_k = - \\frac{\\partial E_\\text{pot}}{\\partial \\vec{r}_k} = - \\frac{1}{2} \\sum _{ij} \\frac{\\partial V}{\\partial r_{ij}} \\frac{\\partial r_{ij}}{\\partial \\vec{r}_k} = - \\frac{1}{2} \\sum _{ij} \\frac{\\partial V}{\\partial r_{ij}} \\hat{r}_{ij} \\left (\\delta _{ik} - \\delta _{jk}\\right ) = \\sum _i \\frac{\\partial V}{\\partial r_{ik}} \\hat{r}_{ik}, \\end{equation} where \\(\\hat{r}_{ik}=\\vec{r}_{ik}/r_{ik}\\) is the unit vector pointing from atom \\(k\\) to atom \\(i\\). Note that these forces are symmetric, i.e. the term \\(\\partial V/\\partial r_{ik} \\hat{r}_{ik}\\) shows up in the expression not only for the force on atom \\(k\\), but also (with an opposite sign) for the force on atom \\(k\\). This a consequence of momentum conservation. (The sum over all forces needs to vanish.) In an implementation one can therefore loop over all pairs between atoms, compute this pair term and add it to the array entries holding the forces for both atoms. 3.2.1 Dispersion forces . An important contribution to interatomic and intermolecular interactions is the London dispersion force. This interaction is attractive, and acts between all atoms even noble gases. Its origin lies in fluctuations of the atomic dipole moment. (This is a quantum mechanical effect, but the simplest model would be an electron orbiting a nucleus with a rotating dipole moment.) This fluctuating dipole induces a dipole in a second atom and these interact. The interaction decays as \\(r^{-6}\\) at short distances. London dispersion forces are one of the forces that are often subsumed under the term van-der-Waals interaction. 3.2.2 Lennard-Jones potential . The Lennard-Jones potential combines dispersion forces with an empirical \\(r^{- 12}\\) model for Pauli repulsion. It is typically used for the interaction of noble atoms or molecules, i.e. systems that have closed electronic shells and therefore do not form covalent bonds. The interaction described by the Lennard-Jones potential are often called nonbonded interactions, because the typical interaction energy is on the order of \\(k_B T\\) (with room temperature for \\(T\\)). Thermal fluctuation can thereby break this bond, hence the term nonbonded. One typical form to writing the Lennard-Jones potential is \\begin{equation} V(r) = 4\\varepsilon \\left [ \\left (\\frac{\\sigma }{r}\\right )^{12} - \\left (\\frac{\\sigma }{r}\\right )^6 \\right ] \\end{equation} where \\(\\varepsilon \\) is an energy and \\(\\sigma \\) a length. The potential has a minimum as \\(r=2^{1/6} \\sigma \\) and is repulsive for shorter distances and attractive for larger distances. For a noble gas (e.g. Argon), \\(\\varepsilon \\sim 0.01\\) eV and \\(\\sigma \\sim 3\\) Å. 3.3 Short-ranged potentials . https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=16d8770d-f056-45c4-a6c6-ad2301538f27 . Implementing Eq. \\eqref{eq:pairpot} naively leads to a complexity of \\(O\\left ( N^{2} \\right )\\) because the sum contains \\(N^2\\) terms. The trick is to cut the interaction range, i.e. set energies and forces to zero for distances larger than a certain cut-off distance \\(r_c\\). This is possible because the asymptotic behavior \\(V\\left ( r \\right ) \\rightarrow 0\\) as \\(r \\rightarrow \\infty \\). Potentials for which this asymptotic decay is fast enough can be cut-off and are called short-ranged. Note that we have already encountered a case in Chap. ?? for which this is not possible, the Coulomb interaction that has the form \\(V\\left ( r \\right ) \\propto 1/r\\). A simple way to see why this is not possible for the Coulomb interaction is to lump the charge-neutral infinite solid into charge-neutral dipoles. The effective interaction between dipoles then falls of as \\(V^{\\text{eff}}\\left ( r \\right ) \\propto 1/r^{3}\\). The contribution to the energy from all dipoles at distance \\(r\\) is \\(V\\left ( r \\right )r^{2} \\propto 1/r\\). The full energy is obtained by integrating this function over \\(r\\), but the integral does not converge! This illustrates the problem. The discrete sum is convergent, but only conditionally so, i.e. the outcome depends on the order of summation. We therefore can only cut interactions that decay as \\(r^{-4}\\) or faster. The potential energy with a cutoff looks as follows: \\begin{equation} E_\\text{pot}\\left ( \\{ \\vec{r}_{i} \\} \\right ) = \\frac{1}{2}\\sum _{i = 1}^{N}{\\sum _{\\{ j|r_{ij} &lt; r_{c}\\}}^{}{V\\left ( r_{ij} \\right )}} \\label{eq:pairpotcut} \\end{equation} The difference to Eq. \\eqref{eq:pairpot} is that the second sum runs only over neighbors of \\(i\\), i.e. those atoms \\(j\\) whose distance \\(r_{ij}&lt;r_c\\) where \\(r_c\\) is the cutoff radius. This sum has \\(N\\bar{n}\\) elements where \\(\\bar{n}\\) is a constant, is the average number of neighbors within the cutoff radius \\(r_{c}\\). The complexity of an algorithm that implements the above sum is hence \\(O(N)\\). A simple pair potential is often shifted at the cutoff to make the energy continuous (since \\(V\\left ( r_{c} \\right ) \\neq 0\\)). The potential energy expression is then \\(E_\\text{pot} = \\sum _{i &lt; j}^{}\\left ( V\\left ( r_{ij} \\right ) - V\\left ( r_{c} \\right ) \\right )\\). Note that only by shifting the potential, forces and potential energy become consistent. Since only the forces affect the dynamics, the potential energy must be continuous and the integral of the forces, otherwise the Hamiltonian \\(H\\) is not a conserved quantity. The shifted potential fulfills these requirements, the unshifted one does not. 3.4 Neighbor list search . The sum Eq. \\eqref{eq:pairpotcut} runs over all neighbors. One important algorithmic step with complexity \\(O(N)\\) in molecular dynamics codes is to build a neighbor list, i.e. find all pairs i-j with \\(r_{ij} &lt; r_{c}\\). This is usually done using a domain decomposition (see Fig. 3.1) that divides the simulation domain in cells of a certain size and sorts all atoms into one of these cells. The neighbor list can then be constructed by looking for neighbors in neighboring cells only. If the cell size \\(b\\) is larger than the cutoff radius, \\(b&gt;r_c\\), then we only need to look exactly the neighboring cells. Figure 3.1:Illustration of the typical data structure used for an \\(O(N)\\) neighbor search in a molecular dynamics simulation. For searching the neighbors within a cutoff \\(r_c\\) of the red atom, we only need to consider the candidate atoms that are in the cell adjacent to the red atom. We will here illustrate a typical neighbor search using the two-dimensional example shown in Fig. 3.1. Let us assume that each atom has a unique index \\(i\\in [1,N]\\), where \\(N\\) is total number of atoms. (Attention, in C++ and other languages indices typically start at \\(0\\) and run to \\(N-1\\).) A typically algorithm first builds individual lists \\(\\{B_{k,mn}\\}\\) that contain the indices off all atoms in cell \\((m,n)\\), i.e. \\(k\\in N_{nm}\\) where \\(N_{nm}\\) is the number of atoms in this cell. The cell can simply be determined by dividing the position of the atom by the cell size \\(b\\), i.e. atom \\(i\\) resides in cell \\(m_i=\\lfloor x_i/b \\rfloor \\) and \\(n_i=\\lfloor y_i/b \\rfloor \\) where \\(\\lfloor \\cdot \\rfloor \\) indicates the closest smaller integer. The lists \\(\\{B_{k,mn}\\}\\) are most conveniently stored in a single contiguous array; for purposes of accessing individual cells a second array is required that stores the index of the first entry of cell \\((m,n)\\). Note that this second array is equal to the number of cells and can become prohibitively large when the system contains a lot of vacuum. The neighbor search then proceeds as follows: For atom \\(i\\), compute the cell \\((m_i,n_i)\\) in which this atom resides and then loop over all atoms in this cell and in cells \\((m_i\\pm 1,n_i)\\), \\((m_i, n_i\\pm 1)\\) and \\((m_i\\pm 1, n_i\\pm 1)\\). In two dimensions, this yields a loop over \\(9\\) cells, in three-dimensions there the loop runs over \\(27\\). If the distance between these two atoms is smaller than the cutoff \\(r_c\\), we add it to the neighbor list. Note that if the cell size \\(b\\) is smaller than \\(r_c\\) we need include more cells in the search. ",
    "url": "http://localhost:4000/_lecture/chapter03.html#x1-10003",
    "relUrl": "/_lecture/chapter03.html#x1-10003"
  },"8": {
    "doc": "Chapter 03",
    "title": "Bibliography",
    "content": " ",
    "url": "http://localhost:4000/_lecture/chapter03.html#x1-80003.4",
    "relUrl": "/_lecture/chapter03.html#x1-80003.4"
  },"9": {
    "doc": "Chapter 03",
    "title": "Chapter 03",
    "content": ". ",
    "url": "http://localhost:4000/_lecture/chapter03.html",
    "relUrl": "/_lecture/chapter03.html"
  },"10": {
    "doc": "Chapter 04",
    "title": "Chapter 4\nTemperature control",
    "content": "Context: Most molecular dynamics calculations are carried out in thermal equilibrium. Equilibrium is typically maintained by coupling the molecular calculation to a virtual heat bath, with which it exchanges energy but no particles. This chapter discusses properties of thermal equilibrium and introduces simple algorithms for heat-bath coupling. https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=2adb1988-1575-473f-8b8b-ad230158c41c . 4.1 Introduction . In order to talk about temperature control, we need to discuss the properties of thermal equilibrium. This is the realm of statistical mechanics or statistical thermodynamics that is discussed in more detail in Chapter ?? and Appendix ??. A key outcome is that the velocity components are distributed according to a Boltzmann distribution. The velocity magnitude is then distributed according to a Maxwell-Boltzmann distribution. A thermostat implicitly models the coupling to a heat bath much larger than the atomistic system under investigation. Because it is much larger, its temperature will not change when energy flows from and to the heat bath. The atomistic system becomes canonical and its statistics follows the canonical ensemble. An ensemble here describes which parameters are constrained, and the canonical ensemble is often also called the NVT-ensemble, because particle number \\(N\\), volume \\(V\\) and temperature \\(T\\) are constrained (fixed). An ideal thermostat guarantees relaxation of the distribution of atomic degrees of freedom to the canonical distribution function (see Chapter ??). We will here start with a mechanistic treatment of thermostats and underpin it with more rigorous theory in Chapter ??. The present chapter teaches the basic concepts required for an implementation of simple thermostatting schemes. Thermostats can be roughly categorized into constraint methods (velocity rescaling and Berendsen), stochastic methods (Andersen, Langevin and dissipative particle dynamics) and extended system methods (Nosé-Hoover). Constraint and extended system methods are deterministic, i.e. they follow the same path when starting from the same initial state. In this chapter we will only discuss the simple constraint methods. We will come back to more advanced methods for temperature control later in these notes. 4.2 Simple themostatting schemes . 4.2.1 Velocity rescaling . The crudest (and simplest) form of fixing the temperature in a molecular dynamics simulation to a value of \\(T_0\\) is by velocity rescaling. Since the instantaneous temperature is \\begin{equation} \\frac{3}{2} k_BT = \\sum _i \\frac{1}{2} mv_i^2, \\end{equation} we obtain a temperature of \\(T_0\\) if we rescale all velocities by \\begin{equation} \\label{eq:velocity-rescaling} \\vec{v}_i \\to \\lambda \\vec{v}_i\\ \\text{ with } \\ \\lambda =\\sqrt{\\frac{T_0}{T}} \\end{equation} after every time step. This is a very intrusive way of setting the temperature and should not be used in any practical situations, but it is a good illustration of how a simple constraint method works. 4.2.2 Berendsen thermostat . The Berendsen et al. (1984) thermostat uses a damping or acceleration term to control the temperature. The governing equations of motion of the Berendsen thermostat are \\begin{equation} m \\dot{\\vec{v}}_i = \\vec{f}_i + \\frac{m}{2\\tau } \\left ( \\frac{T_0}{T} -1 \\right ) \\vec{v}_i \\label{eq:berendsen} \\end{equation} where \\(\\tau \\) is a relaxation time constant. The factor in front of the velocity is a damping coefficient. The coefficient vanishes for \\(T = T_0\\), Eq. \\eqref{eq:berendsen} then reduces to Newton’s equation of motion. However, it has a positive sign (=speeds up particles) for \\(T &lt; T_0\\) and has negative sign (=slows down particles) for \\(T &gt; T_0\\). From Eq. \\eqref{eq:berendsen} we can easily derive a differential equation for the evolution of the temperature: \\begin{align} 3k_B \\frac{dT}{dt} &amp;= \\sum _i m \\vec{v}_i \\cdot \\dot{\\vec{v}}_i \\\\ &amp;= \\sum _i \\left [ \\vec{v}_i \\cdot \\vec{f}_i + \\frac{1}{2\\tau } \\left ( \\frac{T_0}{T} - 1 \\right ) m v_i^2 \\right ] \\\\ &amp;= - \\frac{dE_\\text{pot}}{dt} + \\frac{3k_B(T_0 - T)}{\\tau } \\end{align} . This can be written as \\begin{equation} \\label{eq:berendsen-temperature-evolution} \\frac{dT}{dt} = -\\frac{T-T_0}{\\tau } + S \\end{equation} where \\(S=-\\frac{1}{3k_B} \\frac{dE_\\text{pot}}{dt}\\) is the change of potential energy and constitutes an additional temperature (energy) source. For \\(S = 0\\), this equation is solved by \\begin{equation} \\label{eq:berendsen-explicit-temperature-evolution} T(t) = T_0 + (T_1-T_0) e^{-t/\\tau } \\end{equation} The temperature relaxes exponentially from the intial value \\(T_1\\) towards \\(T_0\\). We directly see that \\(\\tau \\) in Eq. \\eqref{eq:berendsen} is indeed the relaxation time constant. Note that Eq. \\eqref{eq:berendsen-explicit-temperature-evolution} suggests an implementation of the Berendsen thermostat in terms of velocity rescaling. During at single time step \\(\\Delta t \\ll \\tau \\), the temperature changes from \\(T\\) to \\(T_0 + (T-T_0)e^{-\\Delta t / \\tau }\\). We can implement this as velocity rescaling, Eq. \\eqref{eq:velocity-rescaling}, with \\begin{equation} \\lambda = \\sqrt{\\frac{T_0}{T} + \\left ( 1- \\frac{T_0}{T} \\right ) e^{-\\frac{\\Delta t}{\\tau }}} \\approx \\sqrt{1+ \\left ( \\frac{T_0}{T} - 1 \\right ) \\frac{\\Delta t}{\\tau }} \\end{equation} where \\(T\\) is the current (measure) temperature and \\(T_0\\) is the target temperature. A Berendsen thermostat therefore constitutes a gentle way of rescaling velocities. The relaxation time \\(\\tau \\) determines the strength of the coupling between thermal bath and atomistic system. The velocity rescaling limit \\(\\lambda \\to \\sqrt{T_0/T}\\) is obtained as \\(\\tau \\to 0\\). Thermostats should be tuned as weak as possible and as strong as necessary to disturb the system the least while still allowing it to reach the target temperature within the simulation time. There is the additional requirement \\(\\tau \\gg \\Delta t\\) (where \\(\\Delta t\\) is the time step), otherwise equation Eq. \\eqref{eq:berendsen-temperature-evolution} will not be sampled properly numerically. The velocity rescaling thermostat discussed above is bad because it is very strong, but also because it violates \\(\\tau \\gg \\Delta t\\). 4.3 Equilibrating a molecular simulation . A “happy” molecular dynamics simulation will nicely run at constant temperature. Simulations are only this happy once they are equilibrated and this equilibration implies that the positions \\(\\{\\vec{r}_i\\}\\) are such that the system resides somewhere near a (potentially local) minimum in the potential energy landscape. When we set up a new simulation, we have to guess a set of \\(\\{\\vec{r}_i\\}\\) that are often far away from this minimum. (For crystalline solids this guess is simple, since we typically know the crystal structure that we are interested in. For liquids, the guess is more difficult since the overall structure is disordered.) Since the forces \\(\\{\\vec{f}_i\\}\\) point towards the minimum, the system will evolve in this direction and the potential energy \\(E_\\text{pot}\\) will decrease over time, \\(d E_\\text{pot}/dt &lt; 0\\). Equation \\eqref{eq:berendsen-temperature-evolution} tells us, that this leads to an increase in temperature since \\(S&gt;0\\). A common problem is that this temperature can be large enough to vaporize the system, i.e. the temperature increases above the vaporization point. The first step in any molecular dynamics simulation is hence to equilibrate the system while avoiding a temperature rise above the point of vaporization (or melting if you are setting up a solid). This can be achieved by running a calculation with a Berendsen thermostat and a strong coupling (i.e. a small \\(\\tau \\)). Once the system has equilibrated, the value of \\(\\tau \\) can be adjusted to a more reasonable relaxation time that does not disturb the calculation too much. Good values for \\(\\tau \\) are between \\(1\\) ps and \\(10\\) ps. Note that if we continuously pump energy into our system, for example because we deform it externally, then Eq. \\eqref{eq:berendsen-temperature-evolution} acquires a non-zero source term, \\(S &gt; 0\\). Assuming \\(S\\) is constant over time, the final temperature is shifted to \\(T_0\\,' = T_0 + S\\tau \\). This temperature offset gets smaller with increasing coupling strength \\(1/\\tau \\). ",
    "url": "http://localhost:4000/_lecture/chapter04.html#x1-10004",
    "relUrl": "/_lecture/chapter04.html#x1-10004"
  },"11": {
    "doc": "Chapter 04",
    "title": "Bibliography",
    "content": "   H. J. C. Berendsen, J. P. M. Postma, W. F. van Gunsteren, A. DiNola, and J. R. Haak. Molecular dynamics with coupling to an external bath. J. Chem. Phys., 81(8):3684–3690, 1984. URL https://doi.org/10.1063/1.448118. ",
    "url": "http://localhost:4000/_lecture/chapter04.html#x1-70004.3",
    "relUrl": "/_lecture/chapter04.html#x1-70004.3"
  },"12": {
    "doc": "Chapter 04",
    "title": "Chapter 04",
    "content": ". ",
    "url": "http://localhost:4000/_lecture/chapter04.html",
    "relUrl": "/_lecture/chapter04.html"
  },"13": {
    "doc": "Chapter 05",
    "title": "Chapter 5\nEmbedded-atom method potentials",
    "content": "Context: We here introduce a more complex interatomic potential that is suitable for modeling metals, the embedded atom method potential. It belongs to the class of many-body interatomic potentials and can be used to model mechanical or thermodynamic properties of metals. https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=1dc294f7-cc2e-4a41-8d21-ad23015fff7d . 5.1 Introduction . Metals are often cubic crystals with anisotropic mechanical properties. Crystals with cubic symmetry have three independent elastic constants, \\(C_{11}\\), \\(C_{12}\\) and \\(C_{44}\\) that roughly describe the resistance to volume change, dilational shear and simple shear. The original driving force behind the development of the embedded atom method (EAM) was to overcome the zero Cauchy pressure \\(P_{C} = (C_{11} - C_{44})/2\\) for solids obtained for pair potentials: Pair potentials always satisfy the Cauchy relation \\(C_{11}=C_{44}\\), hence there are only two independent elastic constants for cubic solids. [Compare: For an isotropic solid there are also two independent elastic constants, but this condition is different, bulk modulus \\(K = (C_{11} + 2C_{12})/3\\) and shear modulus \\(G = C_{44} = ( C_{11} - C_{12} )/2\\).] The Cauchy relation can be relaxed by adding an energy term that depends on the volume per atom \\(v = V/N\\) (Vitek, 1996) \\begin{equation} E( \\{ \\vec{r}_{i} \\} ) = \\frac{1}{2}\\sum _{i = 1}^{N}{\\sum _{j = 1}^{N}{V(r_{ij} ) + NU(V/N)}} \\label{eq:pairplusdens} \\end{equation} The volume dependent term contributes only to deformation modes that do not conserve the volume, i.e. \\(C_{11}\\) or \\(C_{12}\\). This hence breaks the Cauchy relationship \\(C_{12} = C_{44}\\) and gives a non-zero Cauchy-pressure \\(P_{C} = (C_{12} - C_{44})/2\\) . While a potential of the type given by Eq. \\eqref{eq:pairplusdens} can be adjusted to give the correct elastic constant (and can therefore be accurate), it cannot be used for e.g. free surfaces (and is therefore not transferable). This has historically driven the development of more advanced methods for modeling solids such as the EAM described here. Note that EAM potentials are not confined to the realm of solids but can also be used for studying properties of melt, or the transition between solid and melt. 5.2 Functional form . The EAM is based on the assumption that the energy of an impurity in a host crystal lattice is a functional of the overall electron density \\(\\rho (\\vec{r})\\) (that leads to an attraction), plus some form of repulsion (i.e. due to Pauli exclusion). This can be written as \\(E_\\text{pot}=\\mathcal{F}\\left \\lbrack \\rho ( \\vec{r} ) \\right \\rbrack + \\phi \\), where \\(\\mathcal{F}\\) is called the embedding functional that tells us the relationship between energy and electron density and \\(\\phi \\) some repulsive interaction. We view each individual atom in the system as an impurity in the host consisting of all other atoms (Daw and Baskes, 1983). \\(\\mathcal{F}\\) is then approximated by a function that depends on the local electron density \\(\\rho _{i}\\) at atom \\(i\\): \\begin{equation} E_\\text{pot}( \\{ \\vec{r}_{i} \\} ) = \\sum _{i} \\mathcal{F}( \\rho _{i} ) + \\frac{1}{2}\\sum _{i,j} \\phi ( r_{ij} ) \\end{equation} Note the first sum is over atoms, not pairs, and the second term is a simple pair interaction. The missing ingredient is now the local electron density \\(\\rho _i\\), which we approximate from the local density of the nuclei. This assumes that each atom in the vicinity of atom \\(i\\) contributes a certain number of electrons to the position of atom \\(i\\). The embedding function \\(\\mathcal{F(}\\rho )\\) is negative and (typically) decreases monotonously with increasing density. The more closely a structure is packed the lower the energy. The repulsive term that is physically due to electrostatic and Pauli repulsion then stabilizes the structure. This is balance between attractive and repulsive contribution a common feature of most interatomic potentials, and we have already seen it for the Lennard-Jones potential. The local density of the atomic system is easily computed from \\begin{equation} \\rho _{i} = \\sum _{j}{f(r_{ij})} \\end{equation} If \\(f(r)\\) is a step function that drops to zero at a distance \\(r_{c}\\) then \\(\\rho _{i}\\) becomes the coordination number, i.e. the number of atoms within a sphere of radius \\(r_{c}\\). By normalizing the step function with the volume of the sphere, it becomes clear that \\(\\rho _{i}\\) is some measure of the average atomic density within a distance \\(r_{c}\\) from atom i. However, a step function is not differentiable. All distance dependent functions are therefore smoothly connected to zero at a distance \\(r_{c}\\) (the cutoff). This makes the whole functional form differentiable at least once! . Examples of early EAMs are Gupta (1981), Finnis and Sinclair (1984) and Cleri and Rosato (1993). They all employ the specific functional forms \\begin{align} \\mathcal{F}\\left ( \\rho \\right ) &amp;= - A\\sqrt{\\rho } \\\\ f\\left ( r_{ij} \\right ) &amp;= e^{- 2q(r_{ij} - r_{0})} \\\\ V\\left ( r_{ij} \\right ) &amp;= Be^{- p(r_{ij} - r_{0})} \\end{align} . where \\(A\\), \\(B\\), \\(q\\), \\(p\\) and \\(R_{0}\\) are parameters. For example, Cleri and Rosato (1993) give parameters for the elements Ni, Cu, Rh, Pd, Ag, Ir, Pt, Au, Al, Pb, Ti, Zr, Co, Cd, Zn and Mg. Note that the cutoff radius \\(r_c\\) in most potentials based on the embedded-atom approach reaches out to second nearest neighbors or further, e.g. to fifth nearest neighbor for fcc metals in the Cleri and Rosato (1993) potential. These potentials do not describe fundamental forces of nature but they must be parametrized for a specific material. The parametrization also includes choice of cutoff radius \\(r_c\\). 5.3 Parameterization . There exist different strategies to actually determine the parameters of a potential. Cleri and Rosato (1993), as an example, have five parameters and they fit the potential directly to experimental values of the cohesive energy, lattice constant and the three cubic elastic constants. Some authors adjust the either embedding function or repulsive pair potential to reproduce the universal equation of state (see Ferrante et al. (1983); Rose et al. (1984)). For example, Foiles et al. (1986) obtain \\(f(r_{ij})\\) from the electron density of free atom calculations, and assume the pair repulsion is entirely electrostatic, \\(V\\left ( r_{ij} \\right ) = Z_{i}\\left ( r_{ij} \\right )Z_{j}(r_{ij})/r_{ij}\\) (with atomic charges \\(Z_{i}\\) actually depending on the distance between atoms, \\(Z\\left ( r_{ij} \\right ) = Z_{0}\\left ( 1 + \\beta R^{\\nu } \\right )\\exp{( - \\alpha r_{ij})}\\) where \\(Z_{0}\\), \\(\\beta \\), \\(\\nu \\) and \\(\\alpha \\) are parameters). The embedding function \\(F(\\rho )\\) is then adjusted to reproduce the universal equation of state. Note that Foiles et al. (1986) have more parameters in their model than Cleri and Rosato (1993)! . A more modern approach is force matching due to Ercolessi and Adams (1994). Force matching potentials are fit to a set of calculations carried out with a more accurate and more transferable but also more expensive method (e.g. a quantum chemical method) at finite temperature. This generates a molecular dynamics trajectory that has configurations with nonzero forces on each atom. (Fitting to equilibrium properties such as Cleri-Rosato means fitting to structures where all forces are zero.) The potential parameters are then fit to reproduce these forces. This method has the advantage that, in principle, an unlimited set of fitting target can be generated easily and the potential can be fit to a large number of parameters. An example of a force-matched EAM is Grochola et al. (2005). It has no fixed functional form, but splines are used to represent the three functions \\(\\mathcal{F}(\\rho )\\), \\(f(r)\\) and \\(V(r_ij)\\). Figure 5.1 shows these functions for the Grochola et al. (2005) potential. Note: While early EAM potentials had a purely attractive embedding contribution \\(\\mathcal{F}(\\rho )\\) and a purely repulsive pair contribution \\(\\phi (r)\\), this condition is relaxed in more complex potential. As can be seen from Fig. 5.1, Grochola et al. (2005)’s potential includes a repulsive contribution from the embedding term. Figure 5.1:\\(\\mathcal{F}(\\rho )\\), \\(f(r)\\) and \\(V(r_ij)\\) as employed in the Au potential by Grochola et al. (2005). Note: Note that these two approaches, fitting to experimental ground-state data and force-matching, are quite different from a philosophical point of view. It has been argued by Sukhomlinov and Müser (2016), that the potential should contains as few parameters as possible (Occam’s razor!) to achieve best transferability. Potential with many parameters are often accurate for the fitting data set but not accurate outside and hence not transferable. This problem is typically referred to as overfitting. 5.4 Forces . From the total energy expression we can straightforwardly derive forces, \\(\\vec{f}_{k} = - \\partial E/\\partial \\vec{r}_{k}\\), leading to \\begin{align} \\vec{f}_{k} &amp;= - \\sum _{i}^{}\\frac{\\partial \\mathcal{F}\\left ( \\rho _{i} \\right )}{\\partial \\rho _{i}}\\frac{\\partial \\rho _{i}}{\\partial{\\vec{r}}_{k}} - \\frac{1}{2}\\sum _{i,j}^{}\\frac{\\partial V}{\\partial r_{ij}}\\frac{\\partial r_{ij}}{\\partial{\\vec{r}}_{ij}} \\\\ &amp;= - \\sum _{i}^{}\\frac{\\partial \\mathcal{F}\\left ( \\rho _{i} \\right )}{\\partial \\rho _{i}}\\sum _{j}^{}{\\frac{\\partial f}{\\partial r_{ij}}\\frac{\\partial r_{ij}}{\\partial{\\vec{r}}_{k}}} - \\frac{1}{2}\\sum _{i,j}^{}\\frac{\\partial V}{\\partial r_{ij}}\\frac{\\partial r_{ij}}{\\partial{\\vec{r}}_{k}} \\end{align} . Note that \\(\\partial r_{ij}/\\partial \\vec{r}_{k} = \\left ( \\delta _{ik} - \\delta _{jk} \\right ) \\hat{r}_{ij}\\). Hence \\begin{align} \\vec{f}_{k} &amp;= - \\sum _{i}^{}\\frac{\\partial \\mathcal{F}\\left ( \\rho _{i} \\right )}{\\partial \\rho _{i}}\\sum _{j}^{}{\\frac{\\partial f}{\\partial r_{ij}}\\left ( \\delta _{ik} - \\delta _{jk} \\right ){\\hat{r}}_{ij}} - \\frac{1}{2}\\sum _{i,j} \\frac{\\partial V}{\\partial r_{ij}}\\left ( \\delta _{ik} - \\delta _{jk} \\right ){\\hat{r}}_{ij} \\\\ &amp;= - \\sum _{i}^{}\\left ( \\frac{\\partial \\mathcal{F}\\left ( \\rho _{k} \\right )}{\\partial \\rho _{k}}\\frac{\\partial f}{\\partial r_{ki}}{\\hat{r}}_{ki} - \\frac{\\partial \\mathcal{F}\\left ( \\rho _{i} \\right )}{\\partial \\rho _{i}}\\frac{\\partial f}{\\partial r_{ik}}{\\hat{r}}_{ik} \\right ) - \\frac{1}{2}\\sum _{i}^{}\\left ( \\frac{\\partial V}{\\partial r_{ki}}{\\hat{r}}_{ki} - \\frac{\\partial V}{\\partial r_{ik}}\\hat{r}_{ik} \\right ) \\end{align} . Using \\(\\hat{r}_{ik} = - \\hat{r}_{ki}\\) gives \\begin{equation} \\vec{f}_{k} = \\sum _{i} \\left ( \\frac{\\partial \\mathcal{F}\\left ( \\rho _{k} \\right )}{\\partial \\rho _{k}} + \\frac{\\partial \\mathcal{F}\\left ( \\rho _{i} \\right )}{\\partial \\rho _{i}} \\right )\\frac{\\partial f}{\\partial r_{ik}}{\\hat{r}}_{ik} + \\sum _{i} \\frac{\\partial V}{\\partial r_{ik}}{\\hat{r}}_{ik} \\end{equation} Energies and forces are typically implemented analytically in a molecular dynamics code. Derivation (and correct implementation) of the force can be tedious for complicated potential expressions! . ",
    "url": "http://localhost:4000/_lecture/chapter05.html#x1-10005",
    "relUrl": "/_lecture/chapter05.html#x1-10005"
  },"14": {
    "doc": "Chapter 05",
    "title": "Bibliography",
    "content": "   F. Cleri and V. Rosato. Tight-binding potentials for transition metals and alloys. Phys. Rev. B, 48(1):22–33, 1993. URL https://doi.org/10.1103/PhysRevB.48.22.    M. S. Daw and M. I. Baskes. Semiempirical, quantum mechanical calculation of hydrogen embrittlement in metals. Phys. Rev. Lett., 50(17):1285–1288, 1983. URL https://doi.org/10.1103/PhysRevLett.50.1285.    F. Ercolessi and J. B. Adams. Interatomic Potentials from First-Principles Calculations: The Force-Matching Method. EPL, 26(8): 583–588, 1994. URL https://doi.org/10.1209/0295-5075/26/8/005.    J. Ferrante, J. Smith, and J. Rose. Diatomic Molecules and Metallic Adhesion, Cohesion, and Chemisorption: A Single Binding-Energy Relation. Phys. Rev. Lett., 50(18):1385–1386, 1983. doi: 10.1103/PhysRevLett.50.1385. URL http://www.ncbi.nlm.nih.gov/pubmed/23357448.    M. W. Finnis and J. E. Sinclair. A simple empirical N-body potential for transition metals. Phil. Mag. A, 50(1):45–55, 1984. URL https://doi.org/10.1080/01418618408244210.    S. M. Foiles, M. I. Baskes, and M. S. Daw. Embedded-atom-method functions for the fcc metals Cu, Ag, Au, Ni, Pd, Pt, and their alloys. Phys. Rev. B, 33(12):7983–7991, 1986. URL https://doi.org/10.1103/PhysRevB.33.7983.    G. Grochola, S. P. Russo, and I. K. Snook. On fitting a gold embedded atom method potential using the force matching method. J. Chem. Phys., 123(20):204719, 2005. URL https://doi.org/10.1063/1.2124667.    R. P. Gupta. Lattice relaxation at a metal surface. Phys. Rev. B, 23(12): 6265–6270, 1981. URL https://doi.org/10.1103/PhysRevB.23.6265.    J. Rose, J. Smith, F. Guinea, and J. Ferrante. Universal features of the equation of state of metals. Phys. Rev. B, 29(6):2963–2969, 1984. URL https://doi.org/10.1103/PhysRevB.29.2963.    S. V. Sukhomlinov and M. H. Müser. Constraints on phase stability, defect energies, and elastic constants of metals described by EAM-type potentials. J. Phys.: Condens. Matter, 28(39):395701, 2016. URL https://doi.org/10.1088/0953-8984/28/39/395701.    V. Vitek. Pair potentials in atomistic computer simulations. MRS Bull., 21(2):20–23, 1996. URL https://doi.org/10.1557/S088376940004625X. ",
    "url": "http://localhost:4000/_lecture/chapter05.html#x1-60005.4",
    "relUrl": "/_lecture/chapter05.html#x1-60005.4"
  },"15": {
    "doc": "Chapter 05",
    "title": "Chapter 05",
    "content": ". ",
    "url": "http://localhost:4000/_lecture/chapter05.html",
    "relUrl": "/_lecture/chapter05.html"
  },"16": {
    "doc": "Chapter 06",
    "title": "Chapter 6\nParallel computers and the Message Passing Interface",
    "content": "Context: This chapter sets the stage for discussing parallelization of the molecular dynamics simulation method introduced in the previous chapters. We first need to talk about parallel hardware architectures and how to program for them. The specific programming model that we will employ is known under the term Single Program Multiple Data. The Message Passing Interface (MPI) is a library that facilitates programming for massively parallel machines under this programming model. 6.1 Parallel hardware architectures . Parallel hardware has become ubiquitous over the past decade. Most central processing units (CPUs) in computers, phones or other hardware have multiple cores that can execute instructions in parallel. Massively parallel computing systems combine multiple CPUs into nodes that share a common memory. These nodes are then combined into the full compute system through a network interconnect. Parallel architecture are often hierachical and have parallelization at different levels. Notable is vectorization at the core-level, share memory parallelization for multicore architectures and distributed memory parallelization for large computing systems that communicate via an interconnect (a network connection). https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=6439ba0b-8da2-4cb6-94da-ab9d009f062e . 6.2 Scaling consideration . Software that runs on parallel computers needs to scale. Scaling describes how the time to returning the result changes as the number of available compute units (cores) changes. The simplest model for scaling assumes that our code can be divided into a fraction \\(f_s\\) that needs to be executed on a single core while a fraction \\(f_p\\) scales perfectly, i.e. its execute time is \\(\\propto 1/p\\) where \\(p\\) is the number of available processes or cores. (Note that \\(f_s+f_p=1\\) since they are fractions.) This leads to Amdahl’s law that describes the speedup \\(S\\) as a function of \\(p\\): \\begin{equation} S = p f_p + f_s p \\end{equation} . https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=95d5d79d-4259-4865-af14-ab9d0099e7cb . 6.3 Programming model . The Message Passing Interface (MPI) is an application programming interface (API) for distributed memory parallelization. (A code parallelized with MPI also works on shared memory machines!) The programming model underlying MPI is called single program multiple data (SPMD): The identical program is executed multiple times but operates on different datums. https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=88d86075-f904-4e83-bae6-ab9d00a3e197 . 6.3.1 Example: Monte-Carlo estimate of the number \\(\\pi \\) . As the simplest example of a parallelization, we consider a Monte-Carlo estimate of the number \\(\\pi \\). https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=18ce5d9a-50cf-4834-8a22-aba100bf31cb . ",
    "url": "http://localhost:4000/_lecture/chapter06.html#x1-10006",
    "relUrl": "/_lecture/chapter06.html#x1-10006"
  },"17": {
    "doc": "Chapter 06",
    "title": "Bibliography",
    "content": " ",
    "url": "http://localhost:4000/_lecture/chapter06.html#x1-60006.3.1",
    "relUrl": "/_lecture/chapter06.html#x1-60006.3.1"
  },"18": {
    "doc": "Chapter 06",
    "title": "Chapter 06",
    "content": ". ",
    "url": "http://localhost:4000/_lecture/chapter06.html",
    "relUrl": "/_lecture/chapter06.html"
  },"19": {
    "doc": "Chapter 07",
    "title": "Chapter 7\nDomain decomposition",
    "content": "Context: Parallelization in molecular dynamics typically occurs through domain decomposition. The simulation domain is divided into subdomains, each of which runs within an MPI process. This distributes the workload among different compute units. Communications occurs only at the interface of the subdomain, either to exchange atoms between subdomains or to communicate ghost atoms that are required for the computation of correct forces in short-range interatomic potentials. 7.1 Simulation domain . Our atomic system has so far lived in an infinite space consisting of vaccum. We have made no reference to a simulation domain and the code developed up to Milestone 07 makes not reference to such a domain. We now introduce domain decomposition and for this need a simulation domain, i.e. a region of space \\(\\Omega \\) in which our atoms can reside. This domain can be periodic, which we will discuss in more detail in the next chapter. We will assume that the simulation has its origin at \\((0,0,0)\\) and is spanned by three linearly independent vectors \\(\\vec{a}_1\\), \\(\\vec{a}_2\\) and \\(\\vec{a}_3\\). Any atomic position can then be expressed as \\begin{equation} \\vec{r}_i = s_{i,1} \\vec{a}_1 + s_{i,2}\\vec{a}_2 + s_3 \\vec{a}_{i,3} \\end{equation} with \\(s_\\alpha \\in [0,1)\\). \\(s_\\alpha \\) must remain in this interval since we do not allow atoms outside of the simulation domain. The vector \\(\\vec{s}_i\\) is the scaled position of the atom \\(i\\). Using the domain matrix \\(\\underline{A}=(\\vec{a}_1, \\vec{a}_2, \\vec{a}_3)\\), we can express this more compactly as \\(\\vec{r}_i=\\underline{A}\\cdot \\vec{s}_i\\). Conversely, we obtain the scaled positions from \\(\\vec{s}_i=\\underline{A}^{-1}\\cdot \\vec{r}_i\\). In what follows, we assume rectilinear domains, i.e. \\(\\vec{a}_1=(L_x, 0, 0)\\), \\(\\vec{a}_2=(0, L_y, 0)\\) and \\(\\vec{a}_3=(0, 0, L_z)\\) where \\(L_x\\), \\(L_y\\) and \\(L_z\\) are the linear dimensions of the domain. The methods that are described in the following are straightforwardly extended to arbitrary (tilted) domains. 7.2 Decomposition into Cartesian domains . https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=cee045e7-7cdb-4cda-ad4a-ad6b007de343 . We decompose the full system into \\(N_x\\times N_y\\times N_z\\) subdomains. For a rectilinear domain, this means teach subdomain has linear dimensions of \\(L_x/N_x\\), \\(L_y/N_y\\) and \\(L_z/N_z\\). Each subdomain propagates its own atoms. When atoms leave the subdomain, they are transferred to the respective neighboring domain. We call this process atom exchange. Domain decomposition algorithms for MD simulations have started to appear in the literature around 1990. Some of the earliest references to this type of algorithm are Brugè and Fornili (1990); Liem et al. (1991); Chynoweth et al. (1991); Pinches et al. (1991); Brown et al. (1993); Plimpton (1995). 7.3 Ghost atoms . https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=03a83e2f-54d9-4423-acb8-ad6b007de308 . The atoms within each subdomain are not sufficient to compute the forces upon these atoms. In order to compute forces for atoms near the domain boundary, we need to transfer atoms that sit outside of the subdomain from the neighboring subdomains. These atoms are called ghost atoms. All atoms up to a distance \\(r_\\text{G}\\) from the subdomain boundary are transferred. For a Lennard-Jones potential, \\(r_\\text{G}=r_c\\) but for the EAM potential discussed here \\(r_\\text{G}=2 r_c\\). This is because a force in the EAM potential is affected by an atom that sits twice the cutoff radius \\(r_c\\) away. 7.4 Communication pattern . https://uni-freiburg.cloud.panopto.eu/Panopto/Pages/Embed.aspx?id=2ff96a92-b994-4cee-84b6-ad6b008fc0d3 . The basic communication pattern involves two MPI_Sendrecv commands per Cartesian direction. The atoms that are send (either exchanged or as ghost atoms) must be serialized into a send buffer. Given that serialization has occured into the buffers send_left and send_right, the communication pattern looks as follows: . 1MPI_Sendrecv(&amp;send_left, left_, &amp;recv_right, right_, comm_)};  2MPI_Sendrecv(&amp;send_right, right_, &amp;recv_left, left_, comm_)}; Here comm_ contains the MPI communicator and left_ and right_ the MPI ranks of the processes that host the subdomain to the left and the right, respectively, of the current subdomain. The buffers recv_left and recv_right hold the serialized atomic information received from the left and right, respectively. This information needs to be deserialized into the respective atom data type. ",
    "url": "http://localhost:4000/_lecture/chapter07.html#x1-10007",
    "relUrl": "/_lecture/chapter07.html#x1-10007"
  },"20": {
    "doc": "Chapter 07",
    "title": "Bibliography",
    "content": "   D. Brown, J. H. R. Clarke, M. Okuda, and T. Yamazaki. A domain decomposition parallelization strategy for molecular dynamics simulations on distributed memory machines. Comput. Phys. Comm., 74(1):67–80, 1993. URL https://doi.org/10.1016/0010-4655(93)90107-N.    F. Brugè and S. L. Fornili. Concurrent molecular dynamics simulation of spinodal phase transition on transputer arrays. Comput. Phys. Comm., 60(1):31–38, 1990. URL https://doi.org/10.1016/0010-4655(90)90076-D.    S. Chynoweth, U. C. Klomp, and L. E. Scales. Simulation of organic liquids using pseudo-pairwise interatomic forces on a toroidal transputer array. Comput. Phys. Comm., 62(2):297–306, 1991. URL https://doi.org/10.1016/0010-4655(91)90102-Q.    S. Y. Liem, D. Brown, and J. H. R. Clarke. Molecular dynamics simulations on distributed memory machines. Comput. Phys. Comm., 67(2):261–267, 1991. URL https://doi.org/10.1016/0010-4655(91)90021-C.    M. R. S. Pinches, D. J. Tildesley, and W. Smith. Large scale molecular dynamics on parallel computers using the link-cell algorithm. Molecular Simulation, 6(1-3):51–87, 1991. URL https://doi.org/10.1080/08927029108022139.    S. Plimpton. Fast parallel algorithms for short-range molecular dynamics. J. Comput. Phys., 117(1):1–19, 1995. URL https://doi.org/10.1006/jcph.1995.1039. ",
    "url": "http://localhost:4000/_lecture/chapter07.html#x1-60007.4",
    "relUrl": "/_lecture/chapter07.html#x1-60007.4"
  },"21": {
    "doc": "Chapter 07",
    "title": "Chapter 07",
    "content": ". ",
    "url": "http://localhost:4000/_lecture/chapter07.html",
    "relUrl": "/_lecture/chapter07.html"
  },"22": {
    "doc": "Impressum",
    "title": "Angaben gemäß § 5 TMG",
    "content": " ",
    "url": "http://localhost:4000/impressum.html#angaben-gem%C3%A4%C3%9F--5-tmg",
    "relUrl": "/impressum.html#angaben-gemäß--5-tmg"
  },"23": {
    "doc": "Impressum",
    "title": "Verantwortlich für den Inhalt nach § 55 Abs. 2 RStV",
    "content": "Prof. Dr. Lars Pastewka Albert-Ludwigs-Universität IMTEK - Institut für Mikrosystemtechnik Professur für Simulation Georges-Koehler-Allee 103, 3. OG 79110 Freiburg . ",
    "url": "http://localhost:4000/impressum.html#verantwortlich-f%C3%BCr-den-inhalt-nach--55-abs-2-rstv",
    "relUrl": "/impressum.html#verantwortlich-für-den-inhalt-nach--55-abs-2-rstv"
  },"24": {
    "doc": "Impressum",
    "title": "Kontakt",
    "content": "Telefon: +49 761 203 67480 E-Mail: lars.pastewka@imtek.uni-freiburg.de . ",
    "url": "http://localhost:4000/impressum.html#kontakt",
    "relUrl": "/impressum.html#kontakt"
  },"25": {
    "doc": "Impressum",
    "title": "Datenschutzerklärung (DSGVO)",
    "content": "Auf dieser Webseite werden keine personenbezogenen Daten erhoben, gespeichert oder verarbeitet. Es werden keine Cookies verwendet. Diese Website wird auf GitHub als GitHub Pages gehostet. ",
    "url": "http://localhost:4000/impressum.html#datenschutzerkl%C3%A4rung-dsgvo",
    "relUrl": "/impressum.html#datenschutzerklärung-dsgvo"
  },"26": {
    "doc": "Impressum",
    "title": "Impressum",
    "content": " ",
    "url": "http://localhost:4000/impressum.html",
    "relUrl": "/impressum.html"
  },"27": {
    "doc": "Notizen",
    "title": "Notizen",
    "content": "Hier werden Notizen zu speziellen Themen rund um die Inhalte der Vorlesung gesammelt. ",
    "url": "http://localhost:4000/_notes/",
    "relUrl": "/_notes/"
  },"28": {
    "doc": "Vorlesung",
    "title": "Vorlesung",
    "content": " ",
    "url": "http://localhost:4000/_lecture/",
    "relUrl": "/_lecture/"
  },"29": {
    "doc": "Vorlesung",
    "title": "Lernmaterial",
    "content": "Herzlich willkommen zur Vorlesung Simulationstechniken. Sie finden hier das Lernmaterial welches wir für Sie spezifisch für diese Vorlesung zusammengestellt haben. Ziel dieses Materials ist es, Sie auf die Lösung der Übungsblätter vorzubereiten. Sie sollten selbstverständlich auch andere Informationsquellen, wie z.B. Sachbücher, zu rate ziehen. Wikipedia enthält auch nützliche Informationen zu den Inhalten dieser Vorlesung. Es gibt zwei Arten von Lernmaterial: . | Videos mit kurzen (bis zu 30 Minuten) Vorlesungsschnipseln zu Aspekten dieses Kurses | Geschriebenen Text (das klassische “Skript”) | . Das Lernmaterial ist nach Wochen sortiert um einen Takt vorzugeben, in dem Sie durch das Material arbeiten sollten. Sie können sich das Lernmaterial selbstverständlich schneller aneignen, sollten aber nicht zurückfallen. ",
    "url": "http://localhost:4000/_lecture/#lernmaterial",
    "relUrl": "/_lecture/#lernmaterial"
  },"30": {
    "doc": "Vorlesung",
    "title": "Inhalte",
    "content": "Die Lehrveranstaltung ist grob nach folgenden Themen strukturiert: . | Was ist Modellbildung und Simulation? | Einführung von Ionentransport in einem Elektrolyten als Modellproblem | Linear Funktionenräume und Basisfunktionen | Approximation, Interpolation | Spektrale Methoden und die Methode der finiten Elemente | Numerische Optimierungsverfahren | . Bitte sprechen Sie uns an wenn Sie Fehler oder Unklarheiten im Lernmaterial entdecken. Wir sind nicht unfehlbar und machen durchaus Fehler. Bitte kontaktieren Sie uns in diesem Fall umgehend, idealerweise über den Issue Tracker des zugehörigen Github-Repositoriums. ",
    "url": "http://localhost:4000/_lecture/#inhalte",
    "relUrl": "/_lecture/#inhalte"
  },"31": {
    "doc": "Übungsaufgaben",
    "title": "Übungsaufgaben",
    "content": " ",
    "url": "http://localhost:4000/_homework/",
    "relUrl": "/_homework/"
  },"32": {
    "doc": "Übungsaufgaben",
    "title": "Abgabe der Übungsaufgaben",
    "content": "Im folgenden finden Sie die Übungsblätter für die Lehrveranstaltung. Die Abgabe der Übungsblätter muss vor Mitternacht des in ILIAS genannten Datums geschehen. Zum Bestehen der Veranstaltung benötigen Sie 50% der Punkte auf jedem Übungsblatt. Bitte beachten Sie die [Regeln für gute Abbildungen]. Wir ziehen für formale Fehler auch Punkte ab. ",
    "url": "http://localhost:4000/_homework/#abgabe-der-%C3%BCbungsaufgaben",
    "relUrl": "/_homework/#abgabe-der-übungsaufgaben"
  },"33": {
    "doc": "Übungsaufgaben",
    "title": "Technische Hinweise",
    "content": "Wir empfehlen Ihnen zur Lösung der Übungsblätter die Programmiersprache [Python] in Kombination mit [Jupyter-Notebooks] zu nutzen. Sie haben diese Technologien bereits in vorhergegangen Lehrveranstaltungen kennengelernt. Für Numerik und Visualisierung sind die Python-Module [numpy], [scipy] und [matplotlib] nützlich. Die Übungszettel sowie die Lernmaterialien enthalten Hinweise zur Implementierung in Python. Sie können die Übungen auch in einer anderen Programmiersprache lösen, erhalten dazu aber von uns keine Unterstützung und keine Hinweise. Technische Details zu Python wurden Ihnen in vergangenen Lehrveranstaltungen bereits vermittelt. Zur Auffrischung und Vertiefung finden Sie auf auf diesen Seiten ein [Python-Tutorial] das spezifisch auf Numerik mit Python zugeschnitten ist. Wir stellen weiterhin ein [bwLehrpool]-Image sowie eine virtuelle Maschine mit einer vollständigen Python-Installation und allen Modulen, die Sie zu Lösung der Aufgaben hier benötigen, zur Verfügung. Mehr Informationen hierzu finden Sie unter “Technische Dokumentation” . Bitte haben Sie Verständnis dafür, dass wir technischen Support nur für diese virtuelle Maschine leisten können. Wir können Ihnen leider nicht helfen, Python und dazugehörige Tools auf Ihrer eigenenen Windows, Mac oder Linux-Installation ans Laufen zu bringen. ",
    "url": "http://localhost:4000/_homework/#technische-hinweise",
    "relUrl": "/_homework/#technische-hinweise"
  },"34": {
    "doc": "Milestone 01",
    "title": "Milestone 1  Setting up the build environment",
    "content": " ",
    "url": "http://localhost:4000/_homework/uebungsblatt01.html#milestone-1--setting-up-the-build-environment",
    "relUrl": "/_homework/uebungsblatt01.html#milestone-1--setting-up-the-build-environment"
  },"35": {
    "doc": "Milestone 01",
    "title": "Learning goals",
    "content": "The student will… . | …be able to compile a C++ project with CMake. | . ",
    "url": "http://localhost:4000/_homework/uebungsblatt01.html#learning-goals",
    "relUrl": "/_homework/uebungsblatt01.html#learning-goals"
  },"36": {
    "doc": "Milestone 01",
    "title": "Introduction",
    "content": "In this first milestone we will set up a build environemnt and make sure that you can compile C++ code on your computer. This will be the starting point for the developments in the following milestones. ",
    "url": "http://localhost:4000/_homework/uebungsblatt01.html#introduction",
    "relUrl": "/_homework/uebungsblatt01.html#introduction"
  },"37": {
    "doc": "Milestone 01",
    "title": "Setting up your system",
    "content": "The starting point of your project is setting up a proper build environment. This means, you need to install and test all tools necessary for the project. In particular, you will need: . | A C++ compiler | CMake (at least version 3.11) for our build environment | An MPI installation | . We provide installation instructions for Ubuntu installations. If you have a Windows machine, we recommend to use the Windows Subsystem for Linux (WSL). Documentation on how to install WSL on Windows 10 can be found here. The following instructions also apply for Ubuntu installed within WSL. Once you have these things set up, open a command shell and type . sudo apt-get update sudo apt-get install cmake gcc clang gdb build-essential git cmake-curses-gui valgrind sudo apt-get install openmpi-bin libopenmpi-dev . Note that if you are on a different system than Ubuntu, these commands may differ. On Ubuntu/Debian it is apt or apt-get but on Fedora/CentOS/RHEL the package manager command is dnf. On macOS it depends on which package manager you have installed, the most popular one is Homebrew which provides the brew command for package installation. The names of the packages will also vary between these systems. We recommend using a development environment for developing code. We ourselves use CLion. Free educational licenses for CLion can be obtained here. CLion is available for all of the above platforms and can on Windows be configured to use WSL. (Documentation on CLion and WSL can be found here.) . ",
    "url": "http://localhost:4000/_homework/uebungsblatt01.html#setting-up-your-system",
    "relUrl": "/_homework/uebungsblatt01.html#setting-up-your-system"
  },"38": {
    "doc": "Milestone 01",
    "title": "Creating an empty repository",
    "content": "The first thing you need to do is to set up your build environment. We have done this for you and provide a template repository here: https://github.com/imtek-simulation/cmake-skeleton/. We will now be walking you through the process of obtaining this skeleton repository from the command line. You can also carry out the whole process within CLion. On Github, you can simply create a new repository from our template. Navigate to the link above and click on “Use this template”. You will be asked for a new name of the repository: Let’s call this yamd (Yet Another Molecular Dynamics code). Since my username is “pastewka”, the repository now resides under . https://github.com/pastewka/yamd . You can now check this repository out, i.e. copy it to your local machine. On the shell, type . git clone git@github.com:pastewka/yamd.git . (and replace “pastewka” and “yamd” with whatever is appropriate for you). The code now resides in the subdirectory “yamd”. Note that if you do not want to work on github, you can also directly check out the template repository. Our template repository has existing CMake files. Those CMake files are set up to automatically download the libraries . | Eigen for basic (array) data structures and | Googletest as a testing framework. | . We will work with these libraries throughout this class. Note: If you are unfamiliar with the unix shell, we recommend this tutorial. We also strongly recommend that you use version control (git). If you are unfamiliar with git and want to learn more, see this tutorial. Compiling the code . The template repository contains a file main.cpp that prints the string “Hello world!” to screen and a simple test test_hello_world.cpp. We need to instruct CMake to create what is called a Makefile that contains instructions how to build the code. CMake generally builds the code in a directory that is separate from the source directory. This is different from other build systems. We recommend that you create a directory build inside your source directory. First, navigate to the source code and create this directory: . cd yamd mkdir build cd build . Now, create the makefiles: . cmake .. The argument to cmake tells it where the source code is located, here in the directory level just upwards of the current one (i.e. in ..). You can also build in any other directory but then need to specify the appropriate path when running cmake. Note that cmake has lots of configuration options. To see those, run the text-based user interface: . ccmake .. The additional c in front stands for curses, the library that is used to create the text-based user interface. You can now execute . make . to compile the code. Now run ./myproject tests/myproject_tests . If this worked, you have successfully compiled the hello world program and its tests. ",
    "url": "http://localhost:4000/_homework/uebungsblatt01.html#creating-an-empty-repository",
    "relUrl": "/_homework/uebungsblatt01.html#creating-an-empty-repository"
  },"39": {
    "doc": "Milestone 01",
    "title": "Task summary",
    "content": "This milestone requires the following tasks: . | Create a repository for your code development from our template | Compile the template and run main exectuable and tests | . We provide the following files for you: . | Skeleton repository at https://github.com/imtek-simulation/cmake-skeleton/ | . ",
    "url": "http://localhost:4000/_homework/uebungsblatt01.html#task-summary",
    "relUrl": "/_homework/uebungsblatt01.html#task-summary"
  },"40": {
    "doc": "Milestone 01",
    "title": "Milestone 01",
    "content": " ",
    "url": "http://localhost:4000/_homework/uebungsblatt01.html",
    "relUrl": "/_homework/uebungsblatt01.html"
  },"41": {
    "doc": "Milestone 02",
    "title": "Milestone 2  Velocity-Verlet integration for a single atom",
    "content": " ",
    "url": "http://localhost:4000/_homework/uebungsblatt02.html#milestone-2--velocity-verlet-integration-for-a-single-atom",
    "relUrl": "/_homework/uebungsblatt02.html#milestone-2--velocity-verlet-integration-for-a-single-atom"
  },"42": {
    "doc": "Milestone 02",
    "title": "Learning goals",
    "content": "The student will… . | …understand how to work with source and header files. | …learn how to add new tests to the testing framework. | . ",
    "url": "http://localhost:4000/_homework/uebungsblatt02.html#learning-goals",
    "relUrl": "/_homework/uebungsblatt02.html#learning-goals"
  },"43": {
    "doc": "Milestone 02",
    "title": "Introduction",
    "content": "In this second milestone you will implement a Velocity-Verlet integrator. You will learn about header and source files and how to add them to the CMake build system. You will also need to think about testing, i.e. how to systematically test an implementation. Testing makes sure your new function works correctly but it also makes sure that you will notice when you break it in the future. Note that we explain only the very basics of the relevant C++ features here but link to more detailed explanation. ",
    "url": "http://localhost:4000/_homework/uebungsblatt02.html#introduction",
    "relUrl": "/_homework/uebungsblatt02.html#introduction"
  },"44": {
    "doc": "Milestone 02",
    "title": "Adding a header/source file",
    "content": "We recommend to add the integration functionality into a new module that consists of a header and source file. The header file typically has the extension .h and contains only the signatures (also called interfaces) of the functions. It is required such that the module can be used from another source file. Create a file verlet.h with the following contents: . #ifndef __VERLET_H #define __VERLET_H void verlet_step1(double &amp;x, double &amp;y, double &amp;z, double &amp;vx, double &amp;vy, double &amp;vz, double fx, double fy, double fz, double timestep); void verlet_step2(double &amp;vx, double &amp;vy, double &amp;vz, double fx, double fy, double fz, double timestep); #endif // __VERLET_H . The #ifndef __VERLET_H commands are called a header guard and avoid double inclusion of the file (e.g. in a chain of include statements). Everything that starts with a # is processed by the preprocessor which produces the file that is actually compiled by the C++ compiler. The &amp; symbol in the function signature is a reference. It tells the compiler to pass only the memory location of the underlying data rather than copying it. It should be used for large compound types. (Passing integers or double floating point numbers without reference is fine.) Note that arguments passed as a reference can be modified inside the function, which is why we can update positions and velocities inside verlet_step1. The corresponding source file verlet.cpp should look like this: . #include \"verlet.h\" void verlet_step1(double &amp;x, double &amp;y, double &amp;z, double &amp;vx, double &amp;vy, double &amp;vz, double fx, double fy, double fz, double timestep) { ... implement Verlet step1 here ... } void verlet_step2(double &amp;vx, double &amp;vy, double &amp;vz, double fx, double fy, double fz, double timestep) { ... implement Verlet step2 here ... } . Header and source files have typically extensions .h and .cpp. On Unix system, you sometimes find .hh and .cc for C++ code. C++ headers sometimes have the suffix .hpp. To compile the code, you need to add headers files to MYPROJECT_HDRS and sources files to MYPROJECT_SRCS in the main CMakeLists.txt. From the command-line, you can compile the code by running make in the build directory. ",
    "url": "http://localhost:4000/_homework/uebungsblatt02.html#adding-a-headersource-file",
    "relUrl": "/_homework/uebungsblatt02.html#adding-a-headersource-file"
  },"45": {
    "doc": "Milestone 02",
    "title": "Adding new test cases",
    "content": "It is important to properly test any implementation. You can even adopt a test-driven development style in which tests are written before the implementation. We also here encourage you to write tests for all parts of your molecular dynamics code. We will outline possible testing strategies in the respective milestones. One possible test strategy for numerical code is to compare a numerical solution against a known analytical solution. We are here solving Newton’s equation of motion. A possible analytical solution would be the motion of an atom under a constant force, since this is straightforward to solve. To add a new test, create a new file to the tests subdirectory and add it to the myproject_tests_SRCS in CMakeLists.txt in the tests directory. You can copy the file test_hello_world.cpp as a template. The project uses Googletest. Please browse the documentation and look at the primer on the documentation page. A test case consists of a number of assertion. An assertion defines a certain outcome of the function to be tested. As an example, let us assume we were writing a test for a \\(sin\\) function. We know for example than the function vanishes at integer multiples of \\(\\pi\\). A test case could look like this: . TEST(SinTest, IntegerMultiplesOfPi) { EXPECT_EQ(sin(0), 0); EXPECT_EQ(sin(pi), 0); EXPECT_EQ(sin(2+pi), 0); } . Note that instead of EXCEPT_EQ you can use ASSERT_EQ, which terminates the test at the first failure. Note that a proper test for the \\(sin\\) function would also need to test intermediate values. Tests for floating-point number should not be done using equalities as in the above example. This is because floating-point results are subject to rounding errors. More complex numerical schemes (such as the integrator discussed in the next milestone) are additionally subject to numerical (discretization) errors. Any comparison must therefore be carried out with a certain tolerance. Googletest provides the assertion EXPECT_NEAR and ASSERT_NEAR for this. These assertions take a third argument that specifies the maximum tolerable absolute difference between the two arguments: . TEST(SinTest, IntegerMultiplesOfPi) { EXPECT_NEAR(sin(0), 0, 1e-6); EXPECT_NEAR(sin(pi), 0, 1e-6); EXPECT_NEAR(sin(2+pi), 0, 1e-6); } . ",
    "url": "http://localhost:4000/_homework/uebungsblatt02.html#adding-new-test-cases",
    "relUrl": "/_homework/uebungsblatt02.html#adding-new-test-cases"
  },"46": {
    "doc": "Milestone 02",
    "title": "Implement integrator and tests",
    "content": "Implement the Velocity-Verlet integration and write a test for it by comparing the motion of a single atom under the action of a constant force. You will find useful code snippets in the lecture material. Note that the test will require a first mini-(molecular)-dynamics simulation. In order to integrate the equations of motion, you will need to write a loop of the form . for (int i = 0; i &lt; nb_steps; ++i) { std::cout &lt;&lt; \"Step: \" &lt;&lt; i &lt;&lt; std::endl; verlet_step1(args...); ... compute forces here ... verlet_step2(args...); } . This loop integrates the equation of motion for nb_steps steps. The main loop of any molecular dynamics simulation code looks like this. We will add bells and whistles to it, but the main structure will remain the same. The stream std::cout can be used to print something to the screen. You can find the documentation for iostream here. ",
    "url": "http://localhost:4000/_homework/uebungsblatt02.html#implement-integrator-and-tests",
    "relUrl": "/_homework/uebungsblatt02.html#implement-integrator-and-tests"
  },"47": {
    "doc": "Milestone 02",
    "title": "Task summary",
    "content": "This milestone requires the following tasks: . | Implement the Velocity-Verlet integrator | Implement a test for the Velocity-Verlet integrator | . ",
    "url": "http://localhost:4000/_homework/uebungsblatt02.html#task-summary",
    "relUrl": "/_homework/uebungsblatt02.html#task-summary"
  },"48": {
    "doc": "Milestone 02",
    "title": "Milestone 02",
    "content": " ",
    "url": "http://localhost:4000/_homework/uebungsblatt02.html",
    "relUrl": "/_homework/uebungsblatt02.html"
  },"49": {
    "doc": "Milestone 03",
    "title": "Milestone 3  Velocity-Verlet integration for multiple atoms",
    "content": " ",
    "url": "http://localhost:4000/_homework/uebungsblatt03.html#milestone-3--velocity-verlet-integration-for-multiple-atoms",
    "relUrl": "/_homework/uebungsblatt03.html#milestone-3--velocity-verlet-integration-for-multiple-atoms"
  },"50": {
    "doc": "Milestone 03",
    "title": "Learning goals",
    "content": "The student will… . | …learn how to work with Eigen arrays. | . ",
    "url": "http://localhost:4000/_homework/uebungsblatt03.html#learning-goals",
    "relUrl": "/_homework/uebungsblatt03.html#learning-goals"
  },"51": {
    "doc": "Milestone 03",
    "title": "Introduction",
    "content": "The implementation of the integration algorithm from Milestone 2 only works for a single atom. You will now extend the function verlet_step1 and verlet_step2 to work with multiple atoms. For this we will have to introduce data structure that can store the positions and velocities of multiple atoms. We will use Eigen arrays for this. ",
    "url": "http://localhost:4000/_homework/uebungsblatt03.html#introduction",
    "relUrl": "/_homework/uebungsblatt03.html#introduction"
  },"52": {
    "doc": "Milestone 03",
    "title": "Basic data structures",
    "content": "Arrays store multiple values of the same data type and can be used to represent, for example, positions of all atoms. Arrays are indexed and can be though of as the realization of the mathematical objects that are vectors, matrices or tensors. We would like to emphasize, that choosing the right data structures is the single most important part for obtaining code that performs well. As a general rule, the data structure should be designed in a way that data that is processed consecutively is also stored in memory in a continuous manner. This ensures cache coherence. For example, we could be tempted to create a class Atom that contains the positions, velocities, etc. of a single atom and than use an array (e.g. std::vector&lt;Atom&gt; atoms) of that class as the basic data structure. However, positions are then no longer consecutive in memory, since the Atom class contains velocities, possible forces, maybe charges and other properties. A function (e.g. computing forces) does not need the velocities would still load them into the cache, as the cache line size for all modern CPUs is bytes. For high-performance numerical code, it is therefore always preferable to use structures of arrays rather than arrays of structure. In order to store the positions, we will use an Eigen array of shape \\(3\\times N\\) where \\(N\\) is the total number of atoms in our system. You can define an alias to that type with the using keyword: . using Positions_t = Eigen::Array3Xd; . We recommend defining similar aliases for the velocities, forces etc., even if they point to the same type. This enhances readability. Place those type aliases in a separate header file, e.g. types.h. Eigen::Array3Xd is a pre-defined array type that stores doubles (hence the suffix d), has \\(3\\) rows (this is fixed at compile time) and a dynamic number of columns (indicated by the X). Eigen arrays are stored column major, hence the \\(3\\) row entries are stored consecutive in memory. Note that Eigen only supports \\(1\\)- and \\(2\\)-dimensional arrays. ",
    "url": "http://localhost:4000/_homework/uebungsblatt03.html#basic-data-structures",
    "relUrl": "/_homework/uebungsblatt03.html#basic-data-structures"
  },"53": {
    "doc": "Milestone 03",
    "title": "Working with Eigen arrays",
    "content": "We will here outline a couple of important features of Eigen arrays. First, when initializing an array you need to specify the array size: . int nb_atoms = 10; Positions_t positions(3, nb_atoms); . Note that the number of rows (the first argument) is fixed but we still need to provide it upon initialization. The second argument nb_atoms is variable. This combination of fixed-variable sizes is indicated by the 3X suffix of the array type used here to store the positions. You can access values of the array using parenthesis, e.g. positions(2, 1) = 1.0; . sets the \\(y\\)-component of the position of the second atom to \\(1\\). (Important: Indices start at \\(0\\)!) If you want to access the \\(3\\)-vector containing all positions of the second atom, you can use . auto pos2{positions.col(1)}; . This yields column with index \\(1\\), but each column stores the three Cartesian components of the position in our case. You can for example compute the distance vector between two atoms \\(i\\) and \\(j\\) using . Eigen::Array3d distance_vector{positions.col(i) - positions.col(j)}; . Note that in the above example we have use the auto keyword to automatically derive the type, while in the second case we have explicitly used the data type Eigen::Array3d for the distance vector. The curly brackets are a non-narrowing initialization. This type of initialization avoids implicit type conversion and should be prefered over copy initialization or narrowing initialization (with round parenthesis). ",
    "url": "http://localhost:4000/_homework/uebungsblatt03.html#working-with-eigen-arrays",
    "relUrl": "/_homework/uebungsblatt03.html#working-with-eigen-arrays"
  },"54": {
    "doc": "Milestone 03",
    "title": "Integrator for multiple atoms",
    "content": "You are now in a position to turn your integrator into one that accepts multiple atoms. We suggest to use the following signature for the integrators: . #ifndef __VERLET_H #define __VERLET_H #include &lt;Eigen/Dense&gt; void verlet_step1(Eigen::Array3Xd &amp;positions, Eigen::Array3Xd &amp;velocities, const Eigen::Array3Xd &amp;forces, double timestep); void verlet_step2(Eigen::Array3Xd &amp;velocities, const Eigen::Array3Xd &amp;forces, double timestep); #endif // __VERLET_H . The const qualifier tells the compiler that a modification of that argument is not allowed, although it is passed as a reference. (We don’t need to modify the forces and it is good practice to protect the with this const qualifier to avoid accidental modification.) . The corresponding source file verlet.cpp should look like this: . #include \"verlet.h\" void verlet_step1(Eigen::Array3Xd &amp;positions, Eigen::Array3Xd &amp;velocities, const Eigen::Array3Xd &amp;forces, double timestep) { ... implement Verlet step1 here ... } void verlet_step2(Eigen::Array3Xd &amp;velocities, const Eigen::Array3Xd &amp;forces, double timestep) { ... implement Verlet step2 here ... } . Note that you only need to make minor modifications to your current, single-atom integrator, as the loop over atoms occurs automatically. For example, you can obtain an array containing all \\(x\\)-positions from positions.row(0). ",
    "url": "http://localhost:4000/_homework/uebungsblatt03.html#integrator-for-multiple-atoms",
    "relUrl": "/_homework/uebungsblatt03.html#integrator-for-multiple-atoms"
  },"55": {
    "doc": "Milestone 03",
    "title": "Testing the integrator",
    "content": "Update the tests such that they test your modified integrator. These tests should probably propagate a few atoms at the same time. ",
    "url": "http://localhost:4000/_homework/uebungsblatt03.html#testing-the-integrator",
    "relUrl": "/_homework/uebungsblatt03.html#testing-the-integrator"
  },"56": {
    "doc": "Milestone 03",
    "title": "Task summary",
    "content": "This milestone requires the following tasks: . | Extend your Velocity-Verlet integrator to work with multiple atoms | Update your tests to accomodate the changed interface | . ",
    "url": "http://localhost:4000/_homework/uebungsblatt03.html#task-summary",
    "relUrl": "/_homework/uebungsblatt03.html#task-summary"
  },"57": {
    "doc": "Milestone 03",
    "title": "Milestone 03",
    "content": " ",
    "url": "http://localhost:4000/_homework/uebungsblatt03.html",
    "relUrl": "/_homework/uebungsblatt03.html"
  },"58": {
    "doc": "Milestone 04",
    "title": "Milestone 4  Lennard-Jones potential with direct summation",
    "content": " ",
    "url": "http://localhost:4000/_homework/uebungsblatt04.html#milestone-4--lennard-jones-potential-with-direct-summation",
    "relUrl": "/_homework/uebungsblatt04.html#milestone-4--lennard-jones-potential-with-direct-summation"
  },"59": {
    "doc": "Milestone 04",
    "title": "Learning goals",
    "content": "The student will… . | …learn how to implement a simple interatomic potential. | …learn how to systematically test the implementation of this interatomic potential. | . ",
    "url": "http://localhost:4000/_homework/uebungsblatt04.html#learning-goals",
    "relUrl": "/_homework/uebungsblatt04.html#learning-goals"
  },"60": {
    "doc": "Milestone 04",
    "title": "Introduction",
    "content": "We will now implement our first interatomic potential: A Lennard-Jones interaction. The energy of a system interacting via Lennard-Jones forces is given by . \\[E_\\text{pot} = \\frac{1}{2} \\sum_{ij} 4 \\varepsilon \\left[ \\left(\\frac{\\sigma}{r_{ij}}\\right)^{12} - \\left(\\frac{\\sigma}{r_{ij}}\\right)^6\\right]\\] The term \\(\\propto r^{-12}\\) is a simple model for Pauli repulsion and the term \\(\\propto r^{-6}\\) is a model for London dispersion forces. Within this milestone, you will implement this potential via direct summation, i.e. directly using the equation given above without cutting it off at a certain distance. Note that it can be useful to create a separate build target with a separate main.cpp for this milestone. Our notes on CMake describe how to do that. ",
    "url": "http://localhost:4000/_homework/uebungsblatt04.html#introduction",
    "relUrl": "/_homework/uebungsblatt04.html#introduction"
  },"61": {
    "doc": "Milestone 04",
    "title": "A data structure for the atomic system",
    "content": "Before starting, we introduce a data structure that holds the information on the atomic system, i.e. the positions, velocities, forces etc. This makes it easier to pass the atomic system around. We suggest a data structure of the form: . using Positions_t = Eigen::Array3Xd; using Velocities_t = Eigen::Array3Xd; using Forces_t = Eigen::Array3Xd; class Atoms { public: Positions_t positions; Velocities_t velocities; Forces_t forces; Atoms(const Positions_t &amp;p) : positions{p}, velocities{3, p.cols()}, forces{3, p.cols()} { velocities.setZero(); forces.setZero(); } Atoms(const Positions_t &amp;p, const Velocities_t &amp;v) : positions{p}, velocities{v}, forces{3, p.cols()} { assert(p.cols() == v.cols()); forces.setZero(); } size_t nb_atoms() const { return positions.cols(); } }; . The const qualifier behind nb_atoms tells the compiler that this method does not change the state of the Atoms object, i.e. the value of positions, velocities and forces are not affected by a call to nb_atoms. Place this data structure in a separate header file, e.g. atoms.h. We had already discussed in [Milestone 3] that the types should reside in their own header, e.g. types.h. You can then simply include them in atoms.h by placing #include \"types.h\" somewhere at the beginning of the file. Make sure all header files have header guards. ",
    "url": "http://localhost:4000/_homework/uebungsblatt04.html#a-data-structure-for-the-atomic-system",
    "relUrl": "/_homework/uebungsblatt04.html#a-data-structure-for-the-atomic-system"
  },"62": {
    "doc": "Milestone 04",
    "title": "Signature of the function that computes the interatomic potential",
    "content": "Implement the Lennard-Jones potential. Note that you will need to derive the analytical gradient of the total energy . \\[\\vec{f}_k = \\nabla_k E\\] before you can implement the analytical forces. The final expression should take the form . \\[\\vec{f}_k = \\sum_i \\vec{f}_{ik}\\] where \\(\\vec{f}_{ik}\\) is a pair force. (You need to evaluate the specific expression for \\(\\vec{f}_{ik}\\) yourself.) This type of expression is most efficiently computed by looping over unique pairs. We suggest a function with the following signature: . double lj_direct_summation(Atoms &amp;atoms, double epsilon = 1.0, double sigma = 1.0); . This signature defines default parameters for epsilon and sigma, i.e. they need to be specified only if they differ from unity. The function directly modifies the forces in atoms.forces. The return value of this function is the potential energy. Place this function in its own source and header file, e.g. lj_direction_summation.h and lj_direct_summation.cpp. ",
    "url": "http://localhost:4000/_homework/uebungsblatt04.html#signature-of-the-function-that-computes-the-interatomic-potential",
    "relUrl": "/_homework/uebungsblatt04.html#signature-of-the-function-that-computes-the-interatomic-potential"
  },"63": {
    "doc": "Milestone 04",
    "title": "Testing the implementation",
    "content": "When implementing this function you will want to test that the forces that are computed are correct. In particular, the forces and energy need to be consistent in the sense that the forces are the negative derivative of the energy. The energy is typically easy to implement correctly, but forces can be fiddly. One sign of wrong forces is that energy in a molecular dynamics simulation is not conserved, but there are also other causes for this effect (e.g. a time step that is too large) which makes it difficult as a test for the implementation of forces. The common strategy is to compute the forces numerically from the energies. For this, we have to compute a numerical first derivative. This is straightforward to do from the difference quotient, e.g. \\[f'(x) \\approx \\frac{f(x+\\Delta x) - f(x-\\Delta x)}{2 \\Delta x}\\] A formal derivation of this expression can be obtained from a Taylor expansion of \\(f(x)\\). We can use this expression to compute numerical estimates of the forces. A test that uses this to test the analytical forces of the potential can be found here: test_lj_direct_summation.cpp. Place this file in your tests subdirectory and add it to the CMakeLists.txt to use it. Open it in an editor and try to understand how the test works. This type of test is often called a gradient test. ",
    "url": "http://localhost:4000/_homework/uebungsblatt04.html#testing-the-implementation",
    "relUrl": "/_homework/uebungsblatt04.html#testing-the-implementation"
  },"64": {
    "doc": "Milestone 04",
    "title": "A first molecular dynamics calculation",
    "content": "You are now in a position to run a first molecular dynamics calculation. To do this, you need a reasonable initial state for your simulation. The initial state is the initial condition for the solution of Newton’s equation of motion and requires you to specify positions and momenta. You can find such an initial state in the following file: lj54.xyz. The format of this file is called the XYZ file format. We provide a C++ module for reading and writing these files here: xyz.h, xyz.cpp. Include these files into your project. Also open them in an editor and try to understand what they do. You can then read an XYZ-file using the following code block: . #include \"xyz.h\" auto [names, positions, velocities]{read_xyz_with_velocities(\"lj54.xyz\")}; . The variable names contains the element names that you can discard at this point. Important are the variables positions and velocities that you should use as the initial state of your simulation. Note that the velocities contained in lj54.xyz are an extension to the typical XYZ file format that is, however, understood by common visualization tools. Update your code to read this file and then propagate the simulation for a total time of at least \\(100 \\sqrt{m\\sigma^2/\\varepsilon} \\). Use a mass of unity (\\(m=1)\\) and \\(\\varepsilon=1\\) and \\(\\sigma=1\\) for the Lennard-Jones interaction. A reasonable initial time step is \\( 0.001 \\sqrt{m\\sigma^2/\\varepsilon} \\). Monitor the total energy of your simulation. For this you need to implement the computation of the kinetic energy. At this point you can quantify the influence of the time step on your simulation. Change the time step and see how the total energy evolves. What is a good time step for your simulation? . ",
    "url": "http://localhost:4000/_homework/uebungsblatt04.html#a-first-molecular-dynamics-calculation",
    "relUrl": "/_homework/uebungsblatt04.html#a-first-molecular-dynamics-calculation"
  },"65": {
    "doc": "Milestone 04",
    "title": "Visualization",
    "content": "Since you have now run the first molecular dynamics calculation, it is useful to visualize your simulation, i.e. look at how the individual atoms move over time. To achieve this, output the state of the simulation as an XYZ at time intervals of order \\(1 \\sqrt{m\\sigma^2/\\varepsilon} \\). XYZ-files can be visualized with the Open Visualization Tool (OVITO). Download OVITO Basic, install it and look at one of your XYZ files. To output trajectories, you can do two things: . | Consecutively number your files, e.g. traj0000.xyz, traj0001.xyz, traj0002.xyz, etc., OVITO will automatically detect that this is a sequence of files (a trajectory) and allow you visualize the time evolution of your atomic configuration. | Write multiple XYZs into the same file. Also here OVITO will autodetect that this is a trajectory. The following code snippets where write_xyz can be repeated as often as necessary does this: | . std::ofstream traj(\"traj.xyz\"); ... write_xyz(traj, atoms); ... write_xyz(traj, atoms); ... traj.close(); . The second approach has the advantage that there is only a single file that you need to work with, but it can be difficult to extract individual frames from it (e.g. for restarts of your simulation). ",
    "url": "http://localhost:4000/_homework/uebungsblatt04.html#visualization",
    "relUrl": "/_homework/uebungsblatt04.html#visualization"
  },"66": {
    "doc": "Milestone 04",
    "title": "Task summary",
    "content": "This milestone requires the following tasks: . | Derive the analytical expression for the forces of the Lennard-Jones potential | Implement the Lennard-Jones potential and make sure the gradient test passes | Implement computation of the kinetic energy | Run a first molecular dynamics simulation | Decide on a “good” time step | Download and install OVITO | Visualize your simulation | . We ask you to provide the following analytical results in your final report: . | Derivation of the analytical expression for the forces of the Lennard-Jones potential | . We ask you to provide and discuss the following figures in your final report: . | Plot of the total energy as a function of time for different time steps | A sequence of snapshots (no more than 5) from your simulation run | . We provide the following files for you: . | lj54.xyz | test_lj_direct_summation.cpp | xyz.h | xyz.cpp | . ",
    "url": "http://localhost:4000/_homework/uebungsblatt04.html#task-summary",
    "relUrl": "/_homework/uebungsblatt04.html#task-summary"
  },"67": {
    "doc": "Milestone 04",
    "title": "Milestone 04",
    "content": " ",
    "url": "http://localhost:4000/_homework/uebungsblatt04.html",
    "relUrl": "/_homework/uebungsblatt04.html"
  }
}
